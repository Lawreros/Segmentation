{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "\n",
    "This notebook is for experimenting with the creation of a class which loads/organizes/saves images used for segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import List:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Iterable, Tuple, Any, Union\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import nibabel as nib\n",
    "from pathlib import Path\n",
    "import pydicom\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Loading and Saving Images Class\n",
    "While the particulars of each segmentation problem are different, the loading/augmentation/saving\n",
    "\n",
    "Note: Look at https://github.com/MIC-DKFZ/batchgenerators for list of different types of image editing\n",
    "\n",
    "The general breakdown that I am thinking of is:\n",
    "\n",
    "1. **ImgIE** : \"Image Import Export\", this class will contain the methods for loading the images into numpy/tensors and exporting numpy/tensors back to images. This should also have methods for searching through files and storing them.\n",
    "2. **ImgAug** : \"Image Augmentation\", this class will handle any of the different image augmentations that one might think of doing for 2D and 3D images\n",
    "3. **ImgDL** : \"Image Dataloader\", this class will function to make a Pytorch DataLoader that is easy to use for training\n",
    "4. **ImgMet** : \"Image Metrics\", this class will contain methods for calculating common model performance metrics (SSIM, PSNR, Dice, etc.)\n",
    "\n",
    "So the overall use of these classes will be through wrappers around them for loading and processing for the particular problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, as an exercise/building good habits, the classes will include typing for all variables\n",
    "https://peps.python.org/pep-0484/#acceptable-type-hints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ImgIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImgIE():\n",
    "    '''Class for the loading of images into numpy arrays and the saving of numpy arrays into images.\n",
    "    Also handles rudimentary processing of the images.'''\n",
    "    def __init__(self) -> None:\n",
    "        '''Test this out'''\n",
    "        pass\n",
    "\n",
    "    def load_image(self, im_path: Path, verbose: bool=False) -> np.ndarray:\n",
    "        # Given an image path, determines the function required to load the contents\n",
    "        # as a numpy array, which is returned.\n",
    "        fil_typ = os.path.splitext(im_path)[1]\n",
    "\n",
    "        if fil_typ == '.png':\n",
    "            # If file is a png\n",
    "            with Image.open(im_path) as f_im:\n",
    "                img = np.array(f_im)\n",
    "\n",
    "            if verbose:\n",
    "                print(f'Loading {im_path} as png')\n",
    "                print(f'Image shape:{img.shape}')\n",
    "\n",
    "            if self.template['unit'] == 'intensity':\n",
    "                if len(img.shape)==3:\n",
    "                    img = self.rgb2ycrbcr(img)\n",
    "                    img = img[:,:,0] #Just deal with intensity values at the moment because \n",
    "                                    # having multiple channels throws off cv2 when saving, \n",
    "                                    # since it also does BGR instead of RGB and will save a blue image\n",
    "                elif len(img.shape)==2:\n",
    "                    pass            # If the png is just greyscale, then there is nothing that can\n",
    "                                    # be done except take the single channel\n",
    "                else:\n",
    "                    raise ImportError(\"Provided png image is not 2 or 3 dimensional, something is wrong with the image.\")\n",
    "\n",
    "            elif self.template['unit'] == 'color':\n",
    "                raise NotImplementedError(\"\"\"Loading and creation of patches from color png images is\n",
    "                currently not supported. Please use template['unit']='intensity' for conversion of png\n",
    "                imges to greyscale intesity images.\"\"\")\n",
    "\n",
    "        elif fil_typ == '.nii' or fil_typ == '.gz':\n",
    "            img = nib.load(im_path).get_fdata()\n",
    "            if verbose:\n",
    "                print(f'Loading {im_path} as nii')\n",
    "                print(f'Image shape:{img.shape}')\n",
    "\n",
    "        elif fil_typ == '.dcm':\n",
    "            img = pydicom.dcmread(im_path).pixel_array\n",
    "            if verbose:\n",
    "                print(f'Loading {im_path} as dicom')\n",
    "                print(f'Image shape:{img.shape}')\n",
    "\n",
    "        else:\n",
    "            raise FileNotFoundError(f'Image file type {fil_typ} not supported.')\n",
    "\n",
    "        return img\n",
    "\n",
    "    def load_png(self, im_path: Path, unit: str='raw') -> np.ndarray:\n",
    "        '''Load png image\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        im_path : Path\n",
    "            Path to the file you wish to load.\n",
    "        \n",
    "        unit : str\n",
    "            What the unit of the given image should be. Current options are:\n",
    "            - `'raw'` : the raw RGBA values stored in the image (Default)\n",
    "            - `'lumanince'` :  the intensity channel from converting the RGB image to YCbCr.\n",
    "            This will result in the image only having one channel\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        img : float ndarray\n",
    "            The loaded image as a numpy array\n",
    "\n",
    "        '''\n",
    "        with Image.open(im_path) as f_im:\n",
    "            if unit == 'raw':\n",
    "                return np.array(f_im)\n",
    "            if unit == 'luminance':\n",
    "                img = np.array(f_im)\n",
    "                \n",
    "                if len(img.shape) == 3:\n",
    "                    # convert to YCbCr then take first channel (luminance)\n",
    "                    return self.rgba2ycbcr(img)[:,:,0]\n",
    "                \n",
    "                elif len(img.shape) == 2:\n",
    "                    return img\n",
    "                \n",
    "                else:\n",
    "                    raise ImportError(\"Provided png image is not 2 or 3 dimensional, something is wrong with the image.\")\n",
    "        \n",
    "            # If the unit type is not supported\n",
    "            raise NotImplementedError(f'Loading of png using unit value {unit} is currently not supported.')\n",
    "\n",
    "\n",
    "    def load_jpg(self, im_path: Path, unit: str='raw') -> np.ndarray:\n",
    "        '''Load jpg image\n",
    "\n",
    "        '''\n",
    "        pass\n",
    "\n",
    "    def load_nifti(self, im_path: Path) -> np.ndarray:\n",
    "        '''Load nifti file from provided path\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        im_path : Path\n",
    "            Path to the file you wish to load.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        img : float ndarray\n",
    "            The loaded image as a numpy array\n",
    "        \n",
    "        '''\n",
    "        return nib.load(im_path).get_fdata()\n",
    "\n",
    "    def load_dicom(self, im_path: Path) -> np.ndarray:\n",
    "        '''Load DICOM file from provided path\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        im_path : Path\n",
    "            Path to the file you wish to load.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        img : float ndarray\n",
    "            The loaded image as a numpy array\n",
    "        \n",
    "        '''\n",
    "        return pydicom.dcmread(im_path).pixel_array\n",
    "\n",
    "    def rgba2ycbcr(self, img_rgba: np.ndarray) -> np.ndarray:\n",
    "        '''Takes an RBG image and returns it as a YCbCr image \n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        img_rgb : ndarray\n",
    "            The RGBA image which you want to convert to YCbCr\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        img_ycbcr : float ndarray\n",
    "            The converted image\n",
    "\n",
    "        '''\n",
    "        if len(img_rgba.shape) != 4:\n",
    "            raise ValueError('Input image is not RGBA')\n",
    "\n",
    "        img_rgb = img_rgba.astype(np.float32)\n",
    "        \n",
    "        img_ycrcb = cv2.cvtColor(img_rgba, cv2.COLOR_RGB2YCR_CB)\n",
    "        img_ycbcr = img_ycrcb[:,:,(0,2,1)].astype(np.float32)\n",
    "        img_ycbcr[:,:,0] = (img_ycbcr[:,:,0]*(235-16)+16)/255.0\n",
    "        img_ycbcr[:,:,1:] = (img_ycbcr[:,:,1:]*(240-16)+16)/255.0\n",
    "\n",
    "        return img_ycbcr\n",
    "\n",
    "    \n",
    "    def save_image(self, fname: Path, im: np.ndarray, form: str, verbose: bool = False) -> None:\n",
    "        # Take a given image and save it as the specified format:\n",
    "        # fname = output name of the saved file\n",
    "        # im = numpy array of image\n",
    "\n",
    "        dim = im.shape #Get number of dimensions of image\n",
    "\n",
    "        if form == 'png':\n",
    "            # Check that you aren't saving a 3D image\n",
    "            #TODO: Scale inputs to [0,255] so data isn't lost/image isn't saturated\n",
    "            cv2.imwrite(f'{fname}',im)\n",
    "            if verbose:\n",
    "                print(f'Saving: {fname}')\n",
    "        elif form == 'nii':\n",
    "\n",
    "            # TODO: Add option to transpose image for some reason because mricron hates the first dim[0] = 1\n",
    "            # Still gets loaded fine in terms of loading into python, but visualizing it is bad\n",
    "            # np.transpose(im, (1,2,0))\n",
    "\n",
    "\n",
    "            # TODO: If image is 2D then append a third  dimension before saving(?)\n",
    "            nib.save(nib.Nifti1Image(im, np.eye(len(dim)+1)), fname)\n",
    "            if verbose:\n",
    "                print(f'Saving: {fname}')\n",
    "        elif form == 'dcm':\n",
    "            raise NotImplementedError('DICOM saving currently not supported')\n",
    "        else:\n",
    "            raise NotImplementedError('Specified file type is currently not supported for saving')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(np.zeros(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "class Dummy:\n",
    "    def __init__(self) -> None:\n",
    "        self.x = 2\n",
    "        self.y = 3\n",
    "\n",
    "    def add(self, x:int, y:int) -> int:\n",
    "        return x+y\n",
    "\n",
    "    def divide(self, x:int) -> float:\n",
    "        return x//2\n",
    "\n",
    "    def run(self, x: int)-> float:\n",
    "\n",
    "        q = OrderedDict()\n",
    "        q = {'add':self.add,\n",
    "        'divide':self.divide}\n",
    "\n",
    "        return q['add'](x,3)\n",
    "\n",
    "z = Dummy()\n",
    "print(z.run(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "translation\n",
      "[[0, 0, 12], 'rand']\n",
      "resolution\n",
      "[10]\n"
     ]
    }
   ],
   "source": [
    "# This is probably the most sound way to go about doing things until I can think of a better way...\n",
    "# Have the augmentations be entered as a list\n",
    "\n",
    "a = [[\"translation\",[0,0,12],\"rand\"],[\"resolution\",10]]\n",
    "for func, *kwrd in a:\n",
    "    print(func)\n",
    "    print(kwrd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.matmul([2],[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ImgAug\n",
    "\n",
    "The idea behind the majority of these methods is that they intake a numpy array and some parameters and output a numpy array and string indicating what has changed.\n",
    "Is it better to assign the numpy array being worked on to an attribute of the class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import rotate, AffineTransform, warp, rescale, resize\n",
    "import math\n",
    "\n",
    "class ImgAug(ImgIE):\n",
    "    def __init__(self) -> None:\n",
    "        super(ImgIE, self).__init__()\n",
    "        self.template = self.get_template()\n",
    "        pass\n",
    "\n",
    "    def aug_run(self, inp: np.ndarray, aug_key: \"OrderedDict[str, Any]\") -> None:\n",
    "        '''Run provided augmentation using the settings defined by the template dictionary.\n",
    "        Possibly work storing the various methods into a dictionary\n",
    "        https://stackoverflow.com/questions/9168340/using-a-dictionary-to-select-function-to-execute\n",
    "\n",
    "        '''\n",
    "        pass\n",
    "\n",
    "    def grouped_aug_run(self, img_grp: List[List[Path]], aug_key: \"OrderedDict[str, Any]\") -> None:\n",
    "        '''Run provided augmentation on several different groups of images\n",
    "        \n",
    "        '''\n",
    "        pass\n",
    "\n",
    "    def set_template(self) -> None:\n",
    "        pass\n",
    "\n",
    "\n",
    "    def get_template(self) -> \"dict[str, Any]\":\n",
    "        '''Return the previously set template, or return the standard template which \n",
    "        should have parameters changed.\n",
    "        '''\n",
    "        try:\n",
    "            return self.template\n",
    "        except:\n",
    "            return {'out_type':'png',\n",
    "                'unit':'intensity', #Currently only matters for png\n",
    "                'resolution':None,\n",
    "                'same_size': True, # Whether to have the LR image be the same size as the HR image\n",
    "                                   # (i.e. whether to scale down then up or just down)\n",
    "                'translation':None, # Have both single value or multiple\n",
    "                'rotation': None, # Around each axis\n",
    "                'scale': False, # What magnitude to zoom in for added jitter\n",
    "                'patch': False, # Have this accept 3 dimensional input [x,y,z], [x,y], or single\n",
    "                'step': 10, # Also have this accept 3 dimensional input\n",
    "                'keep_blank': False,\n",
    "                'blank_ratio': 0.4,\n",
    "            }\n",
    "\n",
    "    def gen_random_aug(self) -> None:\n",
    "        '''Create a generator for random combinations of augmentation'''\n",
    "        dim = im_h.shape\n",
    "        if len(dim)>3:\n",
    "            raise ValueError('Dimension of input data not currently supported')\n",
    "        \n",
    "        # If single image is provided for any of these settings, convert into list of N dimensions\n",
    "        if self.template['translation'] == None:\n",
    "            trans = [None]\n",
    "        elif type(self.template['translation']) != list:\n",
    "            trans = [self.template['translation'] for _ in range(len(dim))]\n",
    "        else:\n",
    "            trans = self.template['translation'][:] #Weird thing I have to add to not link changes to 'trans' to self.template\n",
    "        \n",
    "        for idx, x in enumerate(trans):\n",
    "            if trans[idx] != 0 and trans[idx] != None:\n",
    "                trans[idx] = np.random.randint(-x,x)\n",
    "\n",
    "\n",
    "    def array_translate(self, im: np.ndarray, trans: List[int], mode: str='symmetric') -> \"tuple[np.ndarray, str]\":\n",
    "        # Translation\n",
    "        dim = im.shape\n",
    "\n",
    "        if len(dim) != len(trans):\n",
    "            raise IndexError(f'Translation of numpy array with dimensions: {dim} is not compatible with translation {trans}')\n",
    "        \n",
    "        if len(dim) == 2:\n",
    "            transform = AffineTransform(translation=(trans[0], trans[1]))\n",
    "            im = warp(im, transform, mode=mode)\n",
    "            label = f'_tr{trans[0]}_{trans[1]}'\n",
    "\n",
    "        elif len(trans) == 3:\n",
    "            transform = AffineTransform(translation=(trans[1], trans[2]))\n",
    "            for i in range(dim[0]):\n",
    "                im[i,:,:] = warp(im[i,:,:], transform, mode = mode)\n",
    "\n",
    "            for i in range(dim[1]):\n",
    "                # Because two dimensions were already translated, you only need to translate\n",
    "                # along one dimension\n",
    "                im[:,i,:] = warp(im[:,i,:], AffineTransform(translation=(trans[0],0)), mode='symmetric')\n",
    "                \n",
    "            label = f'_tr{trans[0]}_{trans[1]}_{trans[2]}'\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError(f\"Translation of objects with dimension {len(dim)} is not currently supported.\")\n",
    "        \n",
    "        return im, label\n",
    "\n",
    "\n",
    "    def array_rotate(self, im: np.ndarray, rot: List[int], order: int=1) -> \"tuple[np.ndarray, str]\":\n",
    "        # TODO: Issue with low resolution not necessairly having the same dimensions\n",
    "        # Rotation 2D\n",
    "        dim = im.shape\n",
    "\n",
    "        if len(dim) != len(rot):\n",
    "            raise IndexError(f'Translation of numpy array with dimensions: {dim} is not compatible with translation {rot}')\n",
    "\n",
    "        if len(dim) == 2:\n",
    "            im = rotate(im, rot[0], order=order)\n",
    "            label = f'_rot{rot[0]}'\n",
    "\n",
    "        # Rotation 3D\n",
    "        elif len(dim) == 3:\n",
    "            for i in range(dim[0]):\n",
    "                im[i,:,:] = rotate(im[i,:,:],rot[0], order=order)\n",
    "            for i in range(dim[1]):\n",
    "                im[:,i,:] = rotate(im[:,i,:],rot[1], order=order)\n",
    "            for i in range(dim[2]):\n",
    "                im[:,:,i] = rotate(im[:,:,i],rot[2], order=order)\n",
    "            label = f'_rot{rot[0]}_{rot[1]}_{rot[2]}'\n",
    "        \n",
    "        else:\n",
    "            raise NotImplementedError(f\"Translation of objects with dimension {len(rot)} is not currently supported.\")\n",
    "\n",
    "        return im, label\n",
    "\n",
    "    def gen_noise(self) -> None:\n",
    "        '''Add noise to provided image'''\n",
    "        pass\n",
    "\n",
    "    def array_scale(self, im: np.ndarray, scale: List[float], order: int=1, mode: str='symmetric', int_dims: bool=False, anti_alias: bool=True) -> \"tuple[np.ndarray, str]\":\n",
    "        '''Either upscales or downscales provided array\n",
    "        https://scikit-image.org/docs/stable/auto_examples/transform/plot_rescale.html\n",
    "        '''\n",
    "        # Scaling\n",
    "        dim = im.shape\n",
    "\n",
    "        if len(dim) != len(scale):\n",
    "            raise IndexError(f'Scaling of numpy array with dimensions: {dim} is not compatible with translation {scale}')\n",
    "\n",
    "        if int_dims:\n",
    "            new_dims = scale\n",
    "            label = f'_si_'\n",
    "        else:\n",
    "            new_dims = [math.floor(x) for x in np.matmul(dim, scale)]\n",
    "            label = f'_sr_'\n",
    "\n",
    "        im = resize(im, new_dims, order=order, mode=mode)\n",
    "\n",
    "        if len(dim) == 2:\n",
    "            label = label + f'{scale[0]}_{scale[1]}'\n",
    "        elif len(dim) == 3:\n",
    "            label = label + f'{scale[0]}_{scale[1]}_{scale[2]}'\n",
    "        else:\n",
    "            raise NotImplementedError(f\"Translation of objects with dimension {len(scale)} is not currently supported.\")\n",
    "\n",
    "        return im, label\n",
    "        \n",
    "    \n",
    "    # def gen_LR_img(self, im, res: float, interp: int=1) -> np.ndarray:\n",
    "    #     # Generate the low-resolution image from the corresponding HR image using resizing\n",
    "    #     # https://pytorch.org/docs/stable/generated/torch.nn.Upsample.html\n",
    "\n",
    "    #     dim = im.shape\n",
    "\n",
    "    #     # TODO: Patching error occurs when the shape of an image has dimension of odd magintude with\n",
    "    #     #       even 'res', and vice versa. Need to come up with a fix for this...\n",
    "    #     new_dims = [math.floor(x) for x in np.divide(dim, res)]\n",
    "\n",
    "    #     im = resize(im, new_dims, order = interp, mode='symmetric')\n",
    "\n",
    "    #     if self.template['same_size']:\n",
    "    #         im = resize(im, dim, order= interp, mode = 'symmetric')\n",
    "\n",
    "    #     return im\n",
    "\n",
    "    def img2patches(self, im_h, fname, same_size=True, keep_blank=False, slice_select=None, save=False, sanity_check=False, verbose=False):\n",
    "        # Depending on the number of dimenions in the `patch` value, either make 2D\n",
    "        # or 3D images\n",
    "\n",
    "        dim = im_h.shape\n",
    "        patch_size = self.template['patch'][:]\n",
    "        step = self.template['step'][:]\n",
    "\n",
    "        \n",
    "        im_name=Path(fname).with_suffix('').__str__()\n",
    "        #im_name = fname.split('.')[:-2][0] #Kind of janky way to just strip away the suffix\n",
    "        \n",
    "        if slice_select: #If slice_select is provided, then getting rid of blanks really screws things up\n",
    "            print('keeping blank')\n",
    "            keep_blank = True\n",
    "\n",
    "        if type(patch_size) != list:\n",
    "            patch_size = [patch_size for _ in range(len(dim))]\n",
    "        \n",
    "        #If they provide a patch size of -1 along a dimension, use the size from dim\n",
    "        for idx, i in enumerate(patch_size): \n",
    "            if i == -1:\n",
    "                patch_size[idx] = dim[idx]\n",
    "        \n",
    "        #TODO: add option of step size is 0 for full image patch size\n",
    "        if type(step) != list:\n",
    "            step = [step for _ in range(len(dim))]\n",
    "\n",
    "        # Whether to shrink the patch size and step size down by the scaling amount for LR images without the same dimensions as the HR images\n",
    "        if not same_size:\n",
    "            try: \n",
    "                patch_size = [math.floor(x) for x in np.divide(patch_size,self.template['resolution'])]\n",
    "            except: \n",
    "                raise ValueError(f'Resolution change coefficient: {self.template[\"resolution\"]} not defined properly for patch_size: {patch_size}')\n",
    "\n",
    "            try: \n",
    "                step = [math.floor(x) for x in np.divide(step,self.template['resolution'])]\n",
    "            except:\n",
    "                raise ValueError(f'Resolution change coefficient: {self.template[\"resolution\"]} not defined properly for step: {step}')\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(f'patch size = {patch_size}')\n",
    "                print(f'step size = {step}')\n",
    "\n",
    "        # Create a numpy stack following Pytorch protocols, so 1 dimension more than patch\n",
    "        \n",
    "        # Count number of non-zero entries\n",
    "        cnt = 0\n",
    "        blank = 0\n",
    "        not_blank = []\n",
    "        itter = -1\n",
    "\n",
    "        # Get total number of patches that will be created:\n",
    "        #patch_count = np.prod([len(range(0,i,step[idx])) for idx, i in enumerate(dim)])\n",
    "        if verbose:\n",
    "            print(f'patch guess = {np.prod([math.floor((i-patch_size[idx])/step[idx])+1 for idx,i in enumerate(dim)])}')\n",
    "        patch_count = np.prod([math.floor((i-patch_size[idx])/step[idx])+1 for idx,i in enumerate(dim)])\n",
    "        patch_vol = math.prod(patch_size)*self.template['blank_ratio']\n",
    "\n",
    "        if len(dim) == 2:\n",
    "            stack = np.zeros((patch_count,patch_size[0],patch_size[1]))\n",
    "            if verbose:\n",
    "                print(f'stack size = {stack.shape}')\n",
    "\n",
    "            for i in range(0,dim[0],step[0]):\n",
    "                for j in range(0,dim[1],step[1]):\n",
    "                    if i+patch_size[0] <= dim[0] and j+patch_size[1] <= dim[1]:\n",
    "                        itter = itter+1 #just a calculator for finding when blanks occur\n",
    "                        samp = im_h[i:i+patch_size[0],j:j+patch_size[1]]\n",
    "\n",
    "                        if keep_blank or (samp==0).sum() <= patch_vol:#(samp.max() > 0):\n",
    "                            stack[cnt,:,:] = samp\n",
    "                            cnt += 1\n",
    "                            not_blank.append(itter)\n",
    "                        else:\n",
    "                            blank += 1\n",
    "                            #blank.append(_)\n",
    "        elif len(dim) == 3:\n",
    "            stack = np.zeros((patch_count,patch_size[0],patch_size[1], patch_size[2]))\n",
    "            print(f'stack size = {stack.shape}')\n",
    "\n",
    "            for i in range(0,dim[0],step[0]):\n",
    "                for j in range(0,dim[1],step[1]):\n",
    "                    for k in range(0,dim[2],step[2]):\n",
    "                        #itter = itter+1 #just a calculator for finding when blanks occur\n",
    "                        if i+patch_size[0] <= dim[0] and j+patch_size[1] <= dim[1] and k+patch_size[2] <= dim[2]:\n",
    "                            itter = itter+1\n",
    "                            samp = im_h[i:i+patch_size[0],j:j+patch_size[1], k:k+patch_size[2]]\n",
    "\n",
    "                            if keep_blank or (samp==0).sum() <= patch_vol:#(samp.max() > 0):\n",
    "                                stack[cnt,:,:,:] = samp\n",
    "                                cnt += 1\n",
    "                                not_blank.append(itter)\n",
    "                            else:\n",
    "                                blank += 1\n",
    "                                #blank.append(_)\n",
    "            print(itter)\n",
    "        else:\n",
    "            raise IndexError(f'Images of dimension {dim} not supported by this method. Only 2D and 3D data accepted.')\n",
    "        \n",
    "\n",
    "        #TODO: There MUST be a better way to organize this whole mess, lol\n",
    "\n",
    "        fnames = []\n",
    "        if slice_select:\n",
    "            for i in range(len(slice_select)):\n",
    "                fnames.append(f'{im_name}_{i}.{self.template[\"out_type\"]}')\n",
    "        else:\n",
    "            for i in range(cnt):\n",
    "                fnames.append(f'{im_name}_{i}.{self.template[\"out_type\"]}')\n",
    "\n",
    "        if save:\n",
    "            if slice_select:\n",
    "                for idx, i in tqdm(enumerate(slice_select)):\n",
    "                    self.save_image(fnames[idx], stack[i], verbose)\n",
    "            else:\n",
    "                for idx, i in tqdm(enumerate(fnames)):\n",
    "                    self.save_image(i,stack[idx], verbose)\n",
    "            if sanity_check:\n",
    "                print(f'Number of patches: {len(not_blank)}')\n",
    "                print(f'Number of blank patches: {blank}')\n",
    "                return fnames, not_blank\n",
    "            else:\n",
    "                return fnames\n",
    "        else:\n",
    "            if sanity_check:\n",
    "                return fnames, stack, not_blank\n",
    "            else:\n",
    "                return fnames, stack\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type([2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ImgDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImgDL(ImgIE, ImgAug):\n",
    "    def __init__(self) -> None:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ImgMet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImgMet():\n",
    "    '''Class for containing different performance metrics'''\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def PSNR_calc(self) -> float:\n",
    "        pass\n",
    "\n",
    "    def SSIR_calc(self) -> float:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U2Net Implementation\n",
    "This serves as a test-run for using this collection of classes on a real problemset.\n",
    "*Note: Task05 has two channels in its images*\n",
    "\n",
    "#### Outline for how to read in the unique file organization that U2Net has:\n",
    "The model requires the use of 3 different datasets, each kept in their own directory\n",
    "- Need to match both the original image and the label file together so they can be loaded at the same time\n",
    "    - Would be good to have a \"list of lists\" setup for this\n",
    "- Need to be able to select randomly from only one dataset at a time\n",
    "    - Ideally each epoch is from a different dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rough outline\n",
    "\n",
    "class UData(ImgIE, ImgAug):\n",
    "    '''Class for data management for U^2-Net training and testing\n",
    "    \n",
    "    Parameters\n",
    "    -------\n",
    "    - path pairs for the folders containing the raw images and the labels\n",
    "        [[/img_1, /label_1],[/img_2, /label_2]]\n",
    "    - output directory for generated images (after patches/augmentation is applied)\n",
    "\n",
    "    '''\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def get_files(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def match_files(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def run(self) -> None:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SrGen recreation\n",
    "Using the defined classes above, is it possible to recreate the SrGen class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit ('3.8.7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "539b544e2c3fdc58492248d082a132f5e0b4fea63e914fb274c32873997cf2f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
