{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D U^2-Net: A 3D Universal U-Net for Multi-Domain Medical Image Segmentation:\n",
    "Test things here\n",
    "https://theaisummer.com/unet-architectures/\n",
    "\n",
    "https://github.com/patrick-kidger/torchtyping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "The Medical Segmentation Decathalon data is assumed to be provided in a particular organizational structure with respect to this folder. For the sake of this exercise, I only will be using three of the provided datasets. If you have these files in the correct folder, you should receive the same (or similar) results.\n",
    "\n",
    "```\n",
    "../data/U2Net/\n",
    "        Task02_Heart/\n",
    "            imagesTr/\n",
    "                la_003.nii.gz\n",
    "                ...\n",
    "                la_030.nii.gz\n",
    "            imagesTs/\n",
    "                la_001.nii.gz\n",
    "                ...\n",
    "                la_028.nii.gz\n",
    "            labelsTr/\n",
    "                la_003.nii.gz\n",
    "                ...\n",
    "                la_030.nii.gz\n",
    "        \n",
    "        Task04_Hippocampus/\n",
    "            imagesTr/\n",
    "                hippocampus_001.nii.gz\n",
    "                ...\n",
    "                hippocampus_394.nii.gz\n",
    "            imagesTs/\n",
    "                hippocampus_002.nii.gz\n",
    "                ...\n",
    "                hippocampus_392.nii.gz\n",
    "            labelsTr/\n",
    "                hippocampus_001.nii.gz\n",
    "                ...\n",
    "                hippocampus_394.nii.gz\n",
    "\n",
    "        Task05_Prostate/\n",
    "            imagesTr/\n",
    "                prostate_00.nii.gz\n",
    "                ...\n",
    "                prostate_47.nii.gz\n",
    "            imagesTs/\n",
    "                prostate_03.nii.gz\n",
    "                ...\n",
    "                prostate_45.nii.gz\n",
    "            labelsTr/\n",
    "                prostate_00.nii.gz\n",
    "                ...\n",
    "                prostate_47.nii.gz\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "sys.path.append('..') # Stupid thing Python makes you do to import from a sibling directory\n",
    "from gen_utils.ImgTools import ImgAug # Custom class for image generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image creation class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Iterable, Tuple, Any, Union, Generator, Dict\n",
    "from pathlib import Path\n",
    "\n",
    "class UData(ImgAug):\n",
    "    '''Class for data management for U^2-Net training and testing\n",
    "    \n",
    "    Parameters\n",
    "    -------\n",
    "    - path pairs for the folders containing the raw images and the labels\n",
    "        [[/img_1, /label_1],[/img_2, /label_2]]\n",
    "    - output directory for generated images (after patches/augmentation is applied)\n",
    "\n",
    "    '''\n",
    "    def __init__(self, img_dir: str, label_dir: str, img_out_dir: str, label_out_dir: str, prefix: str='', suffix: str='') -> None:\n",
    "        self.img_dir = img_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.img_out_dir = img_out_dir\n",
    "        self.label_out_dir = label_out_dir\n",
    "        self.in_img_files, self.in_img_paths = self.get_files(img_dir, prefix, suffix)\n",
    "        self.in_label_files, self.in_label_paths = self.get_files(label_dir, prefix, suffix)\n",
    "        self.out_img_files = []\n",
    "        self.out_label_files = []\n",
    "\n",
    "\n",
    "    def get_files(self, file_dir:str, prefix:str, suffix:str) -> Tuple[List[str],List[str]]:\n",
    "        files = []\n",
    "        paths = []\n",
    "        # If they have provided a list of directories (in the case of DICOM or scattered data)\n",
    "        if isinstance(file_dir, list):\n",
    "            for inp_dir in file_dir:\n",
    "                for fil in os.listdir(inp_dir):\n",
    "                    if fil.startswith(prefix) and fil.endswith(suffix):\n",
    "                        paths.append(inp_dir + fil)\n",
    "                        files.append(fil)\n",
    "\n",
    "                    if not files:\n",
    "                        raise FileNotFoundError('No applicable files found in input directory')\n",
    "        else:\n",
    "            for fil in os.listdir(file_dir):\n",
    "                if fil.startswith(prefix) and fil.endswith(suffix):\n",
    "                    paths.append(file_dir + fil)\n",
    "                    files.append(fil)\n",
    "\n",
    "                if not files:\n",
    "                    raise FileNotFoundError('No applicable files found in input directory')\n",
    "\n",
    "        return files, paths\n",
    "\n",
    "    def match_files(self, img_dir: str, label_dir: str, update=False, paths=True) -> Tuple[List[Path], List[Path]]:\n",
    "        # Get the files that have been generated in the output directory\n",
    "        # If update is false, then just return a list of matched names, if true then\n",
    "        # change the class variable values accordingly.\n",
    "        hr_files = os.listdir(img_dir)\n",
    "        lr_files = os.listdir(label_dir)\n",
    "\n",
    "        # Get a set of all the files with agreement before the metadata\n",
    "        if len(hr_files) > len(lr_files):\n",
    "            matches = list(set(hr_files)-(set(hr_files)-set(lr_files)))\n",
    "        else:\n",
    "            matches = list(set(lr_files)-(set(lr_files)-set(hr_files)))\n",
    "\n",
    "        if update:\n",
    "            # If you want to save these matched files as class variables\n",
    "            self.out_img_files = [Path(img_dir + _) for _ in matches]\n",
    "            self.out_label_files = [Path(label_dir + _) for _ in matches]\n",
    "            print('Image and Lable file locations updated')\n",
    "        \n",
    "        if paths:\n",
    "            return [Path(img_dir + _) for _ in matches], [Path(label_dir + _ ) for _ in matches]\n",
    "        \n",
    "        return [], [] #lazy to make typing work out\n",
    "\n",
    "    def load_image_pair(self, im_id: Union[int, str] ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        # im_id can either be the index value or the name of the file\n",
    "        \n",
    "        if self.out_label_files:\n",
    "            if isinstance(im_id, int):\n",
    "                img_file = self.out_img_files[im_id]\n",
    "                label_file = self.out_label_files[im_id]\n",
    "            elif isinstance(im_id, str):\n",
    "                _ = self.out_img_files.index(Path(im_id))\n",
    "                img_file = self.out_img_files[_]\n",
    "                label_file = self.out_label_files[_]\n",
    "            else:\n",
    "                TypeError(\"Invalid image identifier, please input a string to integer\")\n",
    "\n",
    "            img = self.load_image(img_file)\n",
    "            lab = self.load_image(label_file)\n",
    "\n",
    "            return img, lab\n",
    "        else:\n",
    "            raise ValueError(\"No paths for processed image/label files are stored in this class\")\n",
    "\n",
    "\n",
    "    def run(self, clear=False, save=False, contain_lab: bool=False, verbose=False) -> None:\n",
    "        \n",
    "\n",
    "        if clear:\n",
    "            print('Clearing existing output directories')\n",
    "            shutil.rmtree(self.img_out_dir, ignore_errors=True)\n",
    "            shutil.rmtree(self.label_out_dir, ignore_errors=True)\n",
    "            \n",
    "\n",
    "        os.makedirs(self.img_out_dir, exist_ok=True)\n",
    "        os.makedirs(self.label_out_dir, exist_ok=True)\n",
    "        \n",
    "        fnames_h = []\n",
    "        fnames_l = []\n",
    "\n",
    "        # match in_image_files and in_label_files\n",
    "\n",
    "        #TODO: Come up with good way for match_files to handle multiple input directories\n",
    "        self.in_img_paths, self.in_label_paths = self.match_files(self.img_dir, self.label_dir, update=False, paths=True)\n",
    "\n",
    "        aug_params = {\"translation\":[10,10,10]}\n",
    "        patch = [50, 50, 1]\n",
    "        step = [20, 20, 2]\n",
    "\n",
    "        rand_params_gen = self.gen_random_aug(aug_params)\n",
    "\n",
    "        # for each image, label in in_img_files:\n",
    "        out_img_files = []\n",
    "        out_label_files = []\n",
    "\n",
    "        for im_p, lab_p in zip(self.in_img_paths, self.in_label_paths):\n",
    "\n",
    "            # generate a random parameter set\n",
    "            rand_params = next(rand_params_gen)\n",
    "\n",
    "            # Load images\n",
    "            im = self.load_image(im_p)\n",
    "            lab = self.load_image(lab_p)\n",
    "\n",
    "            # apply image augmentations to pairs of images\n",
    "            im, im_suf = self.array_translate(im, rand_params['translation'])\n",
    "            lab, lab_suf = self.array_translate(lab, rand_params['translation'])\n",
    "\n",
    "            # save as patches of size [x,y,z]\n",
    "            \n",
    "            if contain_lab: #Whether to only take patches which contain the label of interest\n",
    "\n",
    "                fname = lab_p.stem\n",
    "                _, b, not_lab = self.img2patches(lab, patch[:], step[:], min_nonzero= 0.3, fname=fname+lab_suf, save=[self.label_out_dir,'.nii'], verbose = False)\n",
    "                out_label_files.extend(b)\n",
    "\n",
    "                fname = im_p.stem\n",
    "                _, a, not_img = self.img2patches(im, patch[:], step[:], fname=fname+im_suf, slice_select=not_lab, save=[self.img_out_dir,'.nii'], verbose = False)\n",
    "                out_img_files.extend(a)\n",
    "\n",
    "            else:\n",
    "                fname = im_p.stem\n",
    "                _, a, not_img = self.img2patches(im, patch[:], step[:], fname=fname+im_suf, save=[self.img_out_dir,'.nii'], verbose = False)\n",
    "                out_img_files.extend(a)\n",
    "\n",
    "                fname = lab_p.stem\n",
    "                _, b, not_lab = self.img2patches(lab, patch[:], step[:], fname=fname+lab_suf, slice_select=not_img, save=[self.label_out_dir,'.nii'], verbose = False)\n",
    "                out_label_files.extend(b)\n",
    "            \n",
    "\n",
    "\n",
    "        # update file locations for use with load_image_pair\n",
    "        self.out_img_files = out_img_files\n",
    "        self.out_label_files = out_label_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U^2-net blocks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_ch: int, out_ch: int) -> None:\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class InConv(nn.Module):\n",
    "    def __init__(self, in_ch: int, out_ch: int) -> None:\n",
    "        super(InConv, self).__init__()\n",
    "        self.conv = DoubleConv(in_ch, out_ch)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_ch: int, out_ch: int):\n",
    "        super(Down, self).__init__()\n",
    "        self.mpconv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_ch, out_ch)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.mpconv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_ch: int, out_ch: int, bilinear: bool=True) -> None:\n",
    "        super(Up, self).__init__()\n",
    "\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_ch // 2, in_ch // 2, 2, stride=2)\n",
    "\n",
    "        self.conv = DoubleConv(in_ch, out_ch)\n",
    "\n",
    "    def forward(self, x1: torch.Tensor, x2: torch.Tensor) -> torch.Tensor:\n",
    "        x1 = self.up(x1)\n",
    "\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, (diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2))\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_ch: int, out_ch: int):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_ch, out_ch, 1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "class Unet(nn.Module):\n",
    "    def __init__(self, in_channels: int, classes: int) -> None:\n",
    "        super(Unet, self).__init__()\n",
    "        self.n_channels = in_channels\n",
    "        self.n_classes =  classes\n",
    "\n",
    "        self.inc = InConv(in_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        self.down4 = Down(512, 512)\n",
    "        self.up1 = Up(1024, 256)\n",
    "        self.up2 = Up(512, 128)\n",
    "        self.up3 = Up(256, 64)\n",
    "        self.up4 = Up(128, 64)\n",
    "        self.outc = OutConv(64, classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        x = self.outc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U2-Net steps\n",
    "\n",
    "class U2Net3D(nn.Module):\n",
    "    def __init__(self, inChans_list: List[int]=[2], base_outChans: int=16, num_class_list: List[int]=[4], depth: int=5):\n",
    "        super(U2Net3D, self).__init__()\n",
    "        self.depth = depth\n",
    "\n",
    "        nb_tasks = len(num_class_list)\n",
    "\n",
    "        # Create a module list of the InputTransitions for each input data type\n",
    "        # In other words, if you are running this model on a set of images with 2 channels and a set of\n",
    "        # images with 3 channels, then self.in_tr_list = nn.ModuleList([[2x InputTran],[3x InputTran]])\n",
    "        \n",
    "        # TODO: In this implementaiton, they are applying a 3x3x3 instead of a 1x1x1 like they say in the paper \n",
    "        self.in_tr_list = nn.ModuleList(\n",
    "            [InputTransition(inChans_list[j], base_outChans) for j in range(nb_tasks)]\n",
    "        )\n",
    "\n",
    "        outChans_list = list()\n",
    "        self.down_blocks = nn.ModuleList() #register modules from regular python list.\n",
    "        self.down_samps = nn.ModuleList()\n",
    "        self.down_pads = list() # used to pad as padding='same' in tensorflow\n",
    "\n",
    "        inChans = base_outChans\n",
    "\n",
    "        # Create each level of the encoder and decoder\n",
    "        for i in range(depth):\n",
    "            outChans = base_outChans * (2**i)\n",
    "            outChans_list.append(outChans)\n",
    "\n",
    "            # Add another encoder level to the down_block module list\n",
    "            self.down_blocks.append(DownBlock(nb_tasks, inChans, outChans, kernel_size=3, stride=1, padding=1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x:torch.Tensor) -> torch.Tensor:\n",
    "        return x\n",
    "\n",
    "\n",
    "class DownBlock(nn.Module):\n",
    "    def __init__(self, nb_tasks, inChans, outChans, module: str='seperable_adapter', residual: bool=True, kernel_size=3, stride=1, padding=1) -> None:\n",
    "        super(DownBlock, self).__init__()\n",
    "        self.module = module\n",
    "        self.residual = residual\n",
    "        self.op1 = conv_unit(nb_tasks, inChans, outChans, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "        self.act1 = norm_act(outChans, meth=\"act\")\n",
    "        self.op2 = conv_unit(nb_tasks, outChans, outChans, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "        self.act2 = norm_act(outChans, meth=\"act\")\n",
    "\n",
    "    def forward(self, x)-> torch.Tensor:\n",
    "\n",
    "        # TODO: These if/else statements are redundant...\n",
    "\n",
    "        if self.module == 'parallel_adapter' or self.module == 'separable_adapter':\n",
    "            out, share_map, para_map = self.op1(x)\n",
    "        else:\n",
    "            out = self.op1(x)\n",
    "        out = self.act1(out)\n",
    "        if self.module == 'parallel_adapter' or self.module == 'separable_adapter':\n",
    "            out, share_map, para_map = self.op2(out)\n",
    "        else:\n",
    "            out = self.op2(out)\n",
    "        if self.residual: # same to ResNet\n",
    "            out = self.act2(x + out)\n",
    "        else:\n",
    "            out = self.act2(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class InputTransition(nn.Module):\n",
    "    '''\n",
    "    task specific\n",
    "    '''\n",
    "    def __init__(self, inChans, base_outChans):\n",
    "        super(InputTransition, self).__init__()\n",
    "        self.op1 = nn.Sequential(\n",
    "            nn.Conv3d(inChans, base_outChans, kernel_size=3, stride=1, padding=1),\n",
    "            norm_act(base_outChans)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.op1(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "def norm_act(nchan, meth='both') -> nn.InstanceNorm3d | nn.LeakyReLU | nn.Sequential:\n",
    "    '''The normalization activation function, or what normalization you are applying to the\n",
    "    data. Either a InstanceNorm3D for meth='norm', a Leaky ReLU for meth = 'act', \n",
    "    or an LeakyReLU(InstanceNorm3D(x)) for meth='both'\n",
    "     '''\n",
    "    norm = nn.InstanceNorm3d(nchan, affine=True)\n",
    "    # act = nn.ReLU() # activation\n",
    "    act = nn.LeakyReLU(negative_slope=1e-2)\n",
    "    if meth=='norm':\n",
    "        return norm\n",
    "    elif meth=='act':\n",
    "        return act\n",
    "    else:\n",
    "        return nn.Sequential(norm, act)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit ('3.8.7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "539b544e2c3fdc58492248d082a132f5e0b4fea63e914fb274c32873997cf2f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
