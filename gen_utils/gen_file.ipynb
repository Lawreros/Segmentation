{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "\n",
    "This notebook is for experimenting with the creation of a class which loads/organizes/saves images used for segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import List:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Iterable, Tuple, Any, Union, Generator\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import nibabel as nib\n",
    "from pathlib import Path\n",
    "import pydicom\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Loading and Saving Images Class\n",
    "While the particulars of each segmentation problem are different, the loading/augmentation/saving\n",
    "\n",
    "Note: Look at https://github.com/MIC-DKFZ/batchgenerators for list of different types of image editing\n",
    "\n",
    "The general breakdown that I am thinking of is:\n",
    "\n",
    "1. **ImgIE** : \"Image Import Export\", this class will contain the methods for loading the images into numpy/tensors and exporting numpy/tensors back to images. This should also have methods for searching through files and storing them.\n",
    "2. **ImgAug** : \"Image Augmentation\", this class will handle any of the different image augmentations that one might think of doing for 2D and 3D images\n",
    "3. **ImgDL** : \"Image Dataloader\", this class will function to make a Pytorch DataLoader that is easy to use for training\n",
    "4. **ImgMet** : \"Image Metrics\", this class will contain methods for calculating common model performance metrics (SSIM, PSNR, Dice, etc.)\n",
    "\n",
    "So the overall use of these classes will be through wrappers around them for loading and processing for the particular problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, as an exercise/building good habits, the classes will include typing for all variables\n",
    "https://peps.python.org/pep-0484/#acceptable-type-hints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formating Rules:\n",
    "1. Data is a first-class citizen: The raw data/numerical values should always be at the begining of any list of arguments. For example, the numpy array being saved or augmented should always be the first argument.\n",
    "2. Methods should, when possible, only return 1 to 2 values. If multiple variables are returned, then there is a good chance the method can be broken into smaller pieces\n",
    "    a. Methods should try to be consistent in the typing of their returned values, returning `None` or raising errors when a method isn't applicable\n",
    "3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ImgIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImgIE():\n",
    "    '''Class for the loading of images into numpy arrays and the saving of numpy arrays into images.\n",
    "    Also handles rudimentary processing of the images.'''\n",
    "    def __init__(self) -> None:\n",
    "        '''Test this out'''\n",
    "        pass\n",
    "\n",
    "    def load_image(self, im_path: Path, verbose: bool=False) -> np.ndarray:\n",
    "        # Given an image path, determines the function required to load the contents\n",
    "        # as a numpy array, which is returned.\n",
    "        fil_typ = os.path.splitext(im_path)[1]\n",
    "\n",
    "        if fil_typ == '.png':\n",
    "            # If file is a png\n",
    "            with Image.open(im_path) as f_im:\n",
    "                img = np.array(f_im)\n",
    "\n",
    "            if verbose:\n",
    "                print(f'Loading {im_path} as png')\n",
    "                print(f'Image shape:{img.shape}')\n",
    "\n",
    "            if self.template['unit'] == 'intensity':\n",
    "                if len(img.shape)==3:\n",
    "                    img = self.rgb2ycrbcr(img)\n",
    "                    img = img[:,:,0] #Just deal with intensity values at the moment because \n",
    "                                    # having multiple channels throws off cv2 when saving, \n",
    "                                    # since it also does BGR instead of RGB and will save a blue image\n",
    "                elif len(img.shape)==2:\n",
    "                    pass            # If the png is just greyscale, then there is nothing that can\n",
    "                                    # be done except take the single channel\n",
    "                else:\n",
    "                    raise ImportError(\"Provided png image is not 2 or 3 dimensional, something is wrong with the image.\")\n",
    "\n",
    "            elif self.template['unit'] == 'color':\n",
    "                raise NotImplementedError(\"\"\"Loading and creation of patches from color png images is\n",
    "                currently not supported. Please use template['unit']='intensity' for conversion of png\n",
    "                imges to greyscale intesity images.\"\"\")\n",
    "\n",
    "        elif fil_typ == '.nii' or fil_typ == '.gz':\n",
    "            img = nib.load(im_path).get_fdata()\n",
    "            if verbose:\n",
    "                print(f'Loading {im_path} as nii')\n",
    "                print(f'Image shape:{img.shape}')\n",
    "\n",
    "        elif fil_typ == '.dcm':\n",
    "            img = pydicom.dcmread(im_path).pixel_array\n",
    "            if verbose:\n",
    "                print(f'Loading {im_path} as dicom')\n",
    "                print(f'Image shape:{img.shape}')\n",
    "\n",
    "        else:\n",
    "            raise FileNotFoundError(f'Image file type {fil_typ} not supported.')\n",
    "\n",
    "        return img\n",
    "\n",
    "    def load_png(self, im_path: Path, unit: str='raw') -> np.ndarray:\n",
    "        '''Load png image\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        im_path : Path\n",
    "            Path to the file you wish to load.\n",
    "        \n",
    "        unit : str\n",
    "            What the unit of the given image should be. Current options are:\n",
    "            - `'raw'` : the raw RGBA values stored in the image (Default)\n",
    "            - `'lumanince'` :  the intensity channel from converting the RGB image to YCbCr.\n",
    "            This will result in the image only having one channel\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        img : float ndarray\n",
    "            The loaded image as a numpy array\n",
    "\n",
    "        '''\n",
    "        with Image.open(im_path) as f_im:\n",
    "            if unit == 'raw':\n",
    "                return np.array(f_im)\n",
    "            if unit == 'luminance':\n",
    "                img = np.array(f_im)\n",
    "                \n",
    "                if len(img.shape) == 3:\n",
    "                    # convert to YCbCr then take first channel (luminance)\n",
    "                    return self.rgba2ycbcr(img)[:,:,0]\n",
    "                \n",
    "                elif len(img.shape) == 2:\n",
    "                    return img\n",
    "                \n",
    "                else:\n",
    "                    raise ImportError(\"Provided png image is not 2 or 3 dimensional, something is wrong with the image.\")\n",
    "        \n",
    "            # If the unit type is not supported\n",
    "            raise NotImplementedError(f'Loading of png using unit value {unit} is currently not supported.')\n",
    "\n",
    "\n",
    "    def load_jpg(self, im_path: Path, unit: str='raw') -> np.ndarray:\n",
    "        '''Load jpg image\n",
    "\n",
    "        '''\n",
    "        pass\n",
    "\n",
    "    def load_nifti(self, im_path: Path) -> np.ndarray:\n",
    "        '''Load nifti file from provided path\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        im_path : Path\n",
    "            Path to the file you wish to load.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        img : float ndarray\n",
    "            The loaded image as a numpy array\n",
    "        \n",
    "        '''\n",
    "        return nib.load(im_path).get_fdata()\n",
    "\n",
    "    def load_dicom(self, im_path: Path) -> np.ndarray:\n",
    "        '''Load DICOM file from provided path\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        im_path : Path\n",
    "            Path to the file you wish to load.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        img : float ndarray\n",
    "            The loaded image as a numpy array\n",
    "        \n",
    "        '''\n",
    "        return pydicom.dcmread(im_path).pixel_array\n",
    "\n",
    "    def rgba2ycbcr(self, img_rgba: np.ndarray) -> np.ndarray:\n",
    "        '''Takes an RBG image and returns it as a YCbCr image \n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        img_rgb : ndarray\n",
    "            The RGBA image which you want to convert to YCbCr\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        img_ycbcr : float ndarray\n",
    "            The converted image\n",
    "\n",
    "        '''\n",
    "        if len(img_rgba.shape) != 4:\n",
    "            raise ValueError('Input image is not RGBA')\n",
    "\n",
    "        img_rgb = img_rgba.astype(np.float32)\n",
    "        \n",
    "        img_ycrcb = cv2.cvtColor(img_rgba, cv2.COLOR_RGB2YCR_CB)\n",
    "        img_ycbcr = img_ycrcb[:,:,(0,2,1)].astype(np.float32)\n",
    "        img_ycbcr[:,:,0] = (img_ycbcr[:,:,0]*(235-16)+16)/255.0\n",
    "        img_ycbcr[:,:,1:] = (img_ycbcr[:,:,1:]*(240-16)+16)/255.0\n",
    "\n",
    "        return img_ycbcr\n",
    "\n",
    "    \n",
    "    def save_image(self, im: np.ndarray, fname: Path, form: str, verbose: bool = False) -> None:\n",
    "        # Take a given image and save it as the specified format:\n",
    "        # fname = output name of the saved file\n",
    "        # im = numpy array of image\n",
    "\n",
    "        dim = im.shape #Get number of dimensions of image\n",
    "\n",
    "        if form == 'png':\n",
    "            # Check that you aren't saving a 3D image\n",
    "            #TODO: Scale inputs to [0,255] so data isn't lost/image isn't saturated\n",
    "            cv2.imwrite(f'{fname}',im)\n",
    "            if verbose:\n",
    "                print(f'Saving: {fname}')\n",
    "        elif form == 'nii':\n",
    "\n",
    "            # TODO: Add option to transpose image for some reason because mricron hates the first dim[0] = 1\n",
    "            # Still gets loaded fine in terms of loading into python, but visualizing it is bad\n",
    "            # np.transpose(im, (1,2,0))\n",
    "\n",
    "\n",
    "            # TODO: If image is 2D then append a third  dimension before saving(?)\n",
    "            nib.save(nib.Nifti1Image(im, np.eye(len(dim)+1)), fname)\n",
    "            if verbose:\n",
    "                print(f'Saving: {fname}')\n",
    "        elif form == 'dcm':\n",
    "            raise NotImplementedError('DICOM saving currently not supported')\n",
    "        else:\n",
    "            raise NotImplementedError('Specified file type is currently not supported for saving')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(np.zeros(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "class Dummy:\n",
    "    def __init__(self) -> None:\n",
    "        self.x = 2\n",
    "        self.y = 3\n",
    "\n",
    "    def add(self, x:int, y:int) -> int:\n",
    "        return x+y\n",
    "\n",
    "    def divide(self, x:int) -> float:\n",
    "        return x//2\n",
    "\n",
    "    def run(self, x: int)-> float:\n",
    "\n",
    "        q = OrderedDict()\n",
    "        q = {'add':self.add,\n",
    "        'divide':self.divide}\n",
    "\n",
    "        return q['add'](x,3)\n",
    "\n",
    "z = Dummy()\n",
    "print(z.run(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is probably the most sound way to go about doing things until I can think of a better way...\n",
    "# Have the augmentations be entered as a list\n",
    "\n",
    "def test(dat=1, trans=2, mode=3):\n",
    "    return dat, trans, mode\n",
    "\n",
    "\n",
    "a = [[\"translation\",{'trans':[0,0,12],'mode': 'symmetric'}],[\"resolution\",{}]]\n",
    "for func, kwrd in a:\n",
    "    test(5, **kwrd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {'trans':3,'mode':2}\n",
    "b, c, e, *d = test(**a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_random_aug(params: \"List[List[int]]\"=[], float_params: bool=True, negative=True) -> Generator[Tuple[List[List[int]], List[List[float]]],None, None]:\n",
    "    while True:\n",
    "        out_params = []\n",
    "        if float_params:\n",
    "            for i in params:\n",
    "                out_params.append([np.random.uniform(-k*negative, k) if k!=0 else k for k in i])\n",
    "        else:\n",
    "            for i in params:\n",
    "                out_params.append([np.random.randint(-k*negative,k) if k!=0 else k for k in i])\n",
    "\n",
    "        \n",
    "        yield out_params\n",
    "\n",
    "test = gen_random_aug(params = [[2,10,0],[4,0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.8550694961590435, -6.834463317655272, 0], [2.4278386318958454, 0, 0]]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "next(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23491215062240633"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.uniform(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ImgAug\n",
    "\n",
    "The idea behind the majority of these methods is that they intake a numpy array and some parameters and output a numpy array and string indicating what has changed.\n",
    "Is it better to assign the numpy array being worked on to an attribute of the class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import rotate, AffineTransform, warp, rescale, resize\n",
    "import math\n",
    "\n",
    "class ImgAug(ImgIE):\n",
    "    def __init__(self) -> None:\n",
    "        #super(ImgIE, self).__init__()\n",
    "        # super().__init__()\n",
    "        pass\n",
    "\n",
    "    # def aug_run(self, inp: np.ndarray, aug_key: \"OrderedDict[str, Any]\", randomize: bool=False) -> None:\n",
    "    #     '''Run provided augmentation using the settings defined by the template dictionary.\n",
    "    #     Possibly work storing the various methods into a dictionary\n",
    "    #     https://stackoverflow.com/questions/9168340/using-a-dictionary-to-select-function-to-execute\n",
    "\n",
    "    #     '''\n",
    "\n",
    "    #     function_key = {'translation': self.array_translate,\n",
    "    #     'rotation': self.array_rotate,\n",
    "    #     'scale': self.array_scale,\n",
    "    #     'patch': self.img2patches}\n",
    "\n",
    "\n",
    "    #     for func, kwrd in aug_key:\n",
    "    #         if func == 'translation':\n",
    "    #             inp, label = function_key[func](inp,**kwrd)\n",
    "    #         elif func == 'rotation':\n",
    "    #             inp, label = function_key[func](inp,**kwrd)\n",
    "    #         elif func == 'scale':\n",
    "    #             inp, label = function_key[func](inp,**kwrd)\n",
    "    #         elif func == 'patch':\n",
    "    #             inp, label,  = function_key[func](inp,**kwrd)\n",
    "    #     pass\n",
    "\n",
    "\n",
    "    def gen_random_aug(self, params: \"List[List[int]]\"=[], float_params: bool=True, negative=True) -> Generator[Tuple[List[List[int]], List[List[float]]],None, None]:\n",
    "        '''Returns a generator which yields randomized sets of parameters in the same shape that you provided\n",
    "        Used for randomized augmentation of both integer and float parameter sets.\n",
    "        '''\n",
    "        \n",
    "        while True:\n",
    "            out_params = []\n",
    "            if float_params:\n",
    "                for i in params:\n",
    "                    out_params.append([np.random.uniform(-k*negative, k) if k!=0 else k for k in i])\n",
    "            else:\n",
    "                for i in params:\n",
    "                    out_params.append([np.random.randint(-k*negative,k) if k!=0 else k for k in i])\n",
    "            \n",
    "            yield out_params\n",
    "\n",
    "\n",
    "    def array_translate(self, im: np.ndarray, trans: List[int], mode: str='symmetric') -> \"tuple[np.ndarray, str]\":\n",
    "        # Translation\n",
    "        dim = im.shape\n",
    "\n",
    "        if len(dim) != len(trans):\n",
    "            raise IndexError(f'Translation of numpy array with dimensions: {dim} is not compatible with translation {trans}')\n",
    "        \n",
    "        if len(dim) == 2:\n",
    "            transform = AffineTransform(translation=(trans[0], trans[1]))\n",
    "            im = warp(im, transform, mode=mode)\n",
    "            label = f'_tr{trans[0]}_{trans[1]}'\n",
    "\n",
    "        elif len(trans) == 3:\n",
    "            transform = AffineTransform(translation=(trans[1], trans[2]))\n",
    "            for i in range(dim[0]):\n",
    "                im[i,:,:] = warp(im[i,:,:], transform, mode = mode)\n",
    "\n",
    "            for i in range(dim[1]):\n",
    "                # Because two dimensions were already translated, you only need to translate\n",
    "                # along one dimension\n",
    "                im[:,i,:] = warp(im[:,i,:], AffineTransform(translation=(trans[0],0)), mode='symmetric')\n",
    "                \n",
    "            label = f'_tr{trans[0]}_{trans[1]}_{trans[2]}'\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError(f\"Translation of objects with dimension {len(dim)} is not currently supported.\")\n",
    "        \n",
    "        return im, label\n",
    "\n",
    "\n",
    "    def array_rotate(self, im: np.ndarray, rot: List[int], order: int=1) -> \"tuple[np.ndarray, str]\":\n",
    "        # TODO: Issue with low resolution not necessairly having the same dimensions\n",
    "        # Rotation 2D\n",
    "        dim = im.shape\n",
    "\n",
    "        if len(dim) != len(rot):\n",
    "            raise IndexError(f'Translation of numpy array with dimensions: {dim} is not compatible with translation {rot}')\n",
    "\n",
    "        if len(dim) == 2:\n",
    "            im = rotate(im, rot[0], order=order)\n",
    "            label = f'_rot{rot[0]}'\n",
    "\n",
    "        # Rotation 3D\n",
    "        elif len(dim) == 3:\n",
    "            for i in range(dim[0]):\n",
    "                im[i,:,:] = rotate(im[i,:,:],rot[0], order=order)\n",
    "            for i in range(dim[1]):\n",
    "                im[:,i,:] = rotate(im[:,i,:],rot[1], order=order)\n",
    "            for i in range(dim[2]):\n",
    "                im[:,:,i] = rotate(im[:,:,i],rot[2], order=order)\n",
    "            label = f'_rot{rot[0]}_{rot[1]}_{rot[2]}'\n",
    "        \n",
    "        else:\n",
    "            raise NotImplementedError(f\"Translation of objects with dimension {len(rot)} is not currently supported.\")\n",
    "\n",
    "        return im, label\n",
    "\n",
    "    def array_scale(self, im: np.ndarray, scale: List[float], order: int=1, mode: str='symmetric', int_dims: bool=False) -> \"tuple[np.ndarray, str]\":\n",
    "        '''Either upscales or downscales provided array\n",
    "\n",
    "        https://scikit-image.org/docs/stable/auto_examples/transform/plot_rescale.html\n",
    "        '''\n",
    "        # Scaling\n",
    "        dim = im.shape\n",
    "\n",
    "        if len(dim) != len(scale):\n",
    "            raise IndexError(f'Scaling of numpy array with dimensions: {dim} is not compatible with translation {scale}')\n",
    "\n",
    "        if int_dims:\n",
    "            new_dims = scale\n",
    "            label = f'_si_'\n",
    "        else:\n",
    "            new_dims = [math.floor(x) for x in np.matmul(dim, scale)]\n",
    "            label = f'_sr_'\n",
    "\n",
    "        im = resize(im, new_dims, order=order, mode=mode) #If anti-alaising not specified, it is set to True when downsampling an image whose data type is not bool\n",
    "\n",
    "\n",
    "        if len(dim) == 2:\n",
    "            label = label + f'{scale[0]}_{scale[1]}'\n",
    "        elif len(dim) == 3:\n",
    "            label = label + f'{scale[0]}_{scale[1]}_{scale[2]}'\n",
    "        else:\n",
    "            raise NotImplementedError(f\"Translation of objects with dimension {len(scale)} is not currently supported.\")\n",
    "\n",
    "        return im, label\n",
    "        \n",
    "    def array_degrade(self, im: np.ndarray, scale: List[float], order: int=1, mode: str='symmetric', int_dims: bool=False) -> np.ndarray:\n",
    "        '''Uses array_scale to scale in array down and up using the specified order'''\n",
    "\n",
    "        dim = im.shape\n",
    "\n",
    "        im, _ = self.array_scale(im, scale, order=order, mode=mode, int_dims=int_dims)\n",
    "\n",
    "        im, _ = self.array_scale(im, dim, order=order, mode=mode, int_dims=True)\n",
    "\n",
    "        return im\n",
    "\n",
    "    \n",
    "    def gen_noise(self) -> None:\n",
    "        '''Add noise to provided image'''\n",
    "        pass\n",
    "    \n",
    "\n",
    "    def img2patches(self, im: np.ndarray, patch: List[int], step: List[int], fname: List[str], min_nonzero: float = 0,\n",
    "        slice_select: List[int] = [], save: List[str] = [], verbose=False) -> \"tuple[np.ndarray, List[str], List[int]]\":\n",
    "        # Depending on the number of dimenions in the `patch` value, either make 2D\n",
    "        # or 3D images\n",
    "\n",
    "        '''\n",
    "        Needs:\n",
    "            - image: tuple of numpy arrays? That way if you want to apply the same patching to multiple different images you can?\n",
    "            - min_nonzero: [float] either a flat value or a fraction of the minimum amount of input needs to be non-zero before you keep it\n",
    "            - slice_select: [list of ints] a list of slices to preserve from the patches (used when pairing slices between images)\n",
    "            - save_individual patches: tuple[path/filename, form] whether to save each of the patches as seperate files and what format to save them as.\n",
    "                                    if the tuple is empty, then just return the stack of patches and list of filenames \n",
    "            - verbose: [bool]\n",
    "            - patch; [list of ints] if they input -1 as a patch size, then take the full size of that dimension\n",
    "\n",
    "        Returns:\n",
    "            - image stack\n",
    "            - the paths to the image stack or file names for each of the images in the stack\n",
    "            - the slice_select list\n",
    "\n",
    "            not_blank: List[int] a list of all the entries in the stack that passed the min_nonzero quota\n",
    "        '''\n",
    "\n",
    "        # Check patch size\n",
    "        dim = im.shape\n",
    "\n",
    "        if len(dim) != len(patch):\n",
    "            raise IndexError(f'Patch selection of numpy array with dimensions: {dim} is not compatible with patch size: {patch}')\n",
    "\n",
    "        if len(dim) != len(step):\n",
    "            raise IndexError(f'Patch selection step size of numpy array with dimensions: {dim} is not compatible with step size: {step}')\n",
    "\n",
    "        # If they have input something for \"slice_select\", then they are trying to replicate patch selection\n",
    "        if len(slice_select):\n",
    "            min_nonzero = 0\n",
    "\n",
    "        for idx, i in enumerate(patch):\n",
    "            if i == -1:\n",
    "                patch[idx] = dim[idx]\n",
    "\n",
    "        # Create a numpy stack following Pytorch protocols, so 1 dimension more than patch\n",
    "        \n",
    "        # Count number of non-zero entries\n",
    "        cnt = 0\n",
    "        blank = 0\n",
    "        not_blank = []\n",
    "        itter = -1\n",
    "\n",
    "        # Get total number of patches that will be created:\n",
    "        #patch_count = np.prod([len(range(0,i,step[idx])) for idx, i in enumerate(dim)])\n",
    "        if verbose:\n",
    "            print(f'patch guess = {np.prod([math.floor((i-patch[idx])/step[idx])+1 for idx,i in enumerate(dim)])}')\n",
    "        patch_count = np.prod([math.floor((i-patch[idx])/step[idx])+1 for idx,i in enumerate(dim)])\n",
    "        \n",
    "        if min_nonzero > 1: #If they have given pixel/voxel numbers instead of fractions\n",
    "            patch_vol = math.prod(patch) - min_nonzero\n",
    "        else:\n",
    "            # else, calculate the number of pixels/voxels which must be nonzero\n",
    "            patch_vol = math.prod(patch) - math.prod(patch)*min_nonzero\n",
    "\n",
    "\n",
    "        #TODO: There MUST be a better way to organize this whole mess, lol\n",
    "        if len(dim) == 2:\n",
    "            stack = np.zeros((patch_count,patch[0],patch[1]))\n",
    "            if verbose:\n",
    "                print(f'stack size = {stack.shape}')\n",
    "\n",
    "            for i in range(0,dim[0],step[0]):\n",
    "                for j in range(0,dim[1],step[1]):\n",
    "                    if i+patch[0] <= dim[0] and j+patch[1] <= dim[1]:\n",
    "                        itter = itter+1 #just a calculator for finding when blanks occur\n",
    "                        samp = im[i:i+patch[0],j:j+patch[1]]\n",
    "\n",
    "                        if min_nonzero == 0 or (samp==0).sum() <= patch_vol:\n",
    "                            stack[cnt,:,:] = samp\n",
    "                            cnt += 1\n",
    "                            not_blank.append(itter)\n",
    "                        else:\n",
    "                            blank += 1\n",
    "    \n",
    "        elif len(dim) == 3:\n",
    "            stack = np.zeros((patch_count,patch[0],patch[1], patch[2]))\n",
    "            print(f'stack size = {stack.shape}')\n",
    "\n",
    "            for i in range(0,dim[0],step[0]):\n",
    "                for j in range(0,dim[1],step[1]):\n",
    "                    for k in range(0,dim[2],step[2]):\n",
    "                        #itter = itter+1 #just a calculator for finding when blanks occur\n",
    "                        if i+patch[0] <= dim[0] and j+patch[1] <= dim[1] and k+patch[2] <= dim[2]:\n",
    "                            itter = itter+1\n",
    "                            samp = im[i:i+patch[0],j:j+patch[1], k:k+patch[2]]\n",
    "\n",
    "                            if min_nonzero == 0 or (samp==0).sum() <= patch_vol:\n",
    "                                stack[cnt,:,:,:] = samp\n",
    "                                cnt += 1\n",
    "                                not_blank.append(itter)\n",
    "                            else:\n",
    "                                blank += 1\n",
    "        else:\n",
    "            raise IndexError(f'Images of dimension {dim} not supported by this method. Only 2D and 3D data accepted.')\n",
    "        \n",
    "\n",
    "        fnames = []\n",
    "        if slice_select:\n",
    "            for i in range(len(slice_select)):\n",
    "                fnames.append(f'{fname}_{i}')\n",
    "        else:\n",
    "            for i in range(cnt):\n",
    "                fnames.append(f'{fname}_{i}')\n",
    "\n",
    "        if verbose:\n",
    "            print(f'Number of patches: {len(not_blank)}')\n",
    "            print(f'Number of blank patches: {blank}')\n",
    "\n",
    "\n",
    "        if save: #If they want to save the intermediate files\n",
    "            if slice_select:\n",
    "                for idx, i in enumerate(slice_select):\n",
    "                    self.save_image(stack[i], Path(save[1],fnames[idx]), verbose=verbose, form=save[2])\n",
    "            else:\n",
    "                for idx, i in enumerate(fnames):\n",
    "                    self.save_image(stack[i], Path(save[1],fnames[idx]), verbose=verbose, form=save[2])\n",
    "\n",
    "            return np.array([]), fnames, not_blank # Send back not_blank for some comparison tests between running of this\n",
    "        \n",
    "        else:\n",
    "            if slice_select:\n",
    "                return stack[slice_select], fnames, slice_select #Only return the patches which match slice_select\n",
    "\n",
    "            else:\n",
    "                return stack[:cnt], fnames, not_blank  #Only return a stack of the patches that passed the min_nonzero check\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ImgDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImgDL(ImgAug):\n",
    "    def __init__(self) -> None:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ImgMet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImgMet():\n",
    "    '''Class for containing different performance metrics'''\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def PSNR_calc(self) -> float:\n",
    "        pass\n",
    "\n",
    "    def SSIR_calc(self) -> float:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U2Net Implementation\n",
    "This serves as a test-run for using this collection of classes on a real problemset.\n",
    "*Note: Task05 has two channels in its images*\n",
    "\n",
    "#### Outline for how to read in the unique file organization that U2Net has:\n",
    "The model requires the use of 3 different datasets, each kept in their own directory\n",
    "- Need to match both the original image and the label file together so they can be loaded at the same time\n",
    "    - Would be good to have a \"list of lists\" setup for this\n",
    "- Need to be able to select randomly from only one dataset at a time\n",
    "    - Ideally each epoch is from a different dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rough outline\n",
    "\n",
    "class UData(ImgAug):\n",
    "    '''Class for data management for U^2-Net training and testing\n",
    "    \n",
    "    Parameters\n",
    "    -------\n",
    "    - path pairs for the folders containing the raw images and the labels\n",
    "        [[/img_1, /label_1],[/img_2, /label_2]]\n",
    "    - output directory for generated images (after patches/augmentation is applied)\n",
    "\n",
    "    '''\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def get_files(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def match_files(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def run(self) -> None:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SrGen recreation\n",
    "Using the defined classes above, is it possible to recreate the SrGen class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit ('3.8.7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "539b544e2c3fdc58492248d082a132f5e0b4fea63e914fb274c32873997cf2f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
