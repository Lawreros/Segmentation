{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "\n",
    "This notebook is for experimenting with the creation of a class which loads/organizes/saves images used for segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import List:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Iterable, Tuple, Any, Union, Generator, Dict\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import nibabel as nib\n",
    "from pathlib import Path\n",
    "import pydicom\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Loading and Saving Images Class\n",
    "While the particulars of each segmentation problem are different, the loading/augmentation/saving\n",
    "\n",
    "Note: Look at https://github.com/MIC-DKFZ/batchgenerators for list of different types of image editing\n",
    "\n",
    "The general breakdown that I am thinking of is:\n",
    "\n",
    "1. **ImgIE** : \"Image Import Export\", this class will contain the methods for loading the images into numpy/tensors and exporting numpy/tensors back to images. This should also have methods for searching through files and storing them.\n",
    "2. **ImgAug** : \"Image Augmentation\", this class will handle any of the different image augmentations that one might think of doing for 2D and 3D images\n",
    "3. **ImgDL** : \"Image Dataloader\", this class will function to make a Pytorch DataLoader that is easy to use for training\n",
    "4. **ImgMet** : \"Image Metrics\", this class will contain methods for calculating common model performance metrics (SSIM, PSNR, Dice, etc.)\n",
    "\n",
    "So the overall use of these classes will be through wrappers around them for loading and processing for the particular problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, as an exercise/building good habits, the classes will include typing for all variables\n",
    "https://peps.python.org/pep-0484/#acceptable-type-hints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formating Rules:\n",
    "1. Data is a first-class citizen: The raw data/numerical values should always be at the begining of any list of arguments. For example, the numpy array being saved or augmented should always be the first argument.\n",
    "2. Methods should, when possible, only return 1 to 2 values. If multiple variables are returned, then there is a good chance the method can be broken into smaller pieces\n",
    "    a. Methods should try to be consistent in the typing of their returned values, returning `None` or raising errors when a method isn't applicable\n",
    "3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ImgIE\n",
    "Note my use of the `Path` class in order for more explicit coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImgIE():\n",
    "    '''Class for the loading of images into numpy arrays and the saving of numpy arrays into images.\n",
    "    Also handles rudimentary processing of the images.'''\n",
    "    def __init__(self) -> None:\n",
    "        '''Test this out'''\n",
    "        pass\n",
    "\n",
    "    def load_image(self, im_path: Path, unit: str='intensity', verbose: bool=False) -> np.ndarray:\n",
    "        # Given an image path, determines the function required to load the contents\n",
    "        # as a numpy array, which is returned.\n",
    "        fil_typ = os.path.splitext(im_path)[1]\n",
    "\n",
    "        if fil_typ == '.png':\n",
    "            # If file is a png\n",
    "            with Image.open(im_path) as f_im:\n",
    "                img = np.array(f_im)\n",
    "\n",
    "            if verbose:\n",
    "                print(f'Loading {im_path} as png')\n",
    "                print(f'Image shape:{img.shape}')\n",
    "\n",
    "            if unit == 'intensity':\n",
    "                if len(img.shape)==3:\n",
    "                    img = self.rgba2ycbcr(img)\n",
    "                    img = img[:,:,0] #Just deal with intensity values at the moment because \n",
    "                                    # having multiple channels throws off cv2 when saving, \n",
    "                                    # since it also does BGR instead of RGB and will save a blue image\n",
    "                elif len(img.shape)==2:\n",
    "                    pass            # If the png is just greyscale, then there is nothing that can\n",
    "                                    # be done except take the single channel\n",
    "                else:\n",
    "                    raise ImportError(\"Provided png image is not 2 or 3 dimensional, something is wrong with the image.\")\n",
    "\n",
    "            elif unit == 'color':\n",
    "                raise NotImplementedError(\"\"\"Loading and creation of patches from color png images is\n",
    "                currently not supported. Please use template['unit']='intensity' for conversion of png\n",
    "                imges to greyscale intesity images.\"\"\")\n",
    "\n",
    "        elif fil_typ == '.nii' or fil_typ == '.gz':\n",
    "            img = nib.load(im_path).get_fdata()\n",
    "            if verbose:\n",
    "                print(f'Loading {im_path} as nii')\n",
    "                print(f'Image shape:{img.shape}')\n",
    "\n",
    "        elif fil_typ == '.dcm':\n",
    "            img = pydicom.dcmread(im_path).pixel_array\n",
    "            if verbose:\n",
    "                print(f'Loading {im_path} as dicom')\n",
    "                print(f'Image shape:{img.shape}')\n",
    "\n",
    "        else:\n",
    "            raise FileNotFoundError(f'Image file type {fil_typ} not supported.')\n",
    "\n",
    "        return img\n",
    "\n",
    "\n",
    "    def load_png(self, im_path: Path, unit: str='raw') -> np.ndarray:\n",
    "        '''Load png image\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        im_path : Path\n",
    "            Path to the file you wish to load.\n",
    "        \n",
    "        unit : str\n",
    "            What the unit of the given image should be. Current options are:\n",
    "            - `'raw'` : the raw RGBA values stored in the image (Default)\n",
    "            - `'lumanince'` :  the intensity channel from converting the RGB image to YCbCr.\n",
    "            This will result in the image only having one channel\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        img : float ndarray\n",
    "            The loaded image as a numpy array\n",
    "\n",
    "        '''\n",
    "        with Image.open(im_path) as f_im:\n",
    "            if unit == 'raw':\n",
    "                return np.array(f_im)\n",
    "            if unit == 'luminance':\n",
    "                img = np.array(f_im)\n",
    "                \n",
    "                if len(img.shape) == 3:\n",
    "                    # convert to YCbCr then take first channel (luminance)\n",
    "                    return self.rgba2ycbcr(img)[:,:,0]\n",
    "                \n",
    "                elif len(img.shape) == 2:\n",
    "                    return img\n",
    "                \n",
    "                else:\n",
    "                    raise ImportError(\"Provided png image is not 2 or 3 dimensional, something is wrong with the image.\")\n",
    "        \n",
    "            # If the unit type is not supported\n",
    "            raise NotImplementedError(f'Loading of png using unit value {unit} is currently not supported.')\n",
    "\n",
    "\n",
    "    def load_jpg(self, im_path: Path, unit: str='raw') -> np.ndarray:\n",
    "        '''Load jpg image\n",
    "\n",
    "        '''\n",
    "        pass\n",
    "\n",
    "    def load_nifti(self, im_path: Path) -> np.ndarray:\n",
    "        '''Load nifti file from provided path\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        im_path : Path\n",
    "            Path to the file you wish to load.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        img : float ndarray\n",
    "            The loaded image as a numpy array\n",
    "        \n",
    "        '''\n",
    "        return nib.load(im_path).get_fdata()\n",
    "\n",
    "    def load_dicom(self, im_path: Path) -> np.ndarray:\n",
    "        '''Load DICOM file from provided path\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        im_path : Path\n",
    "            Path to the file you wish to load.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        img : float ndarray\n",
    "            The loaded image as a numpy array\n",
    "        \n",
    "        '''\n",
    "        return pydicom.dcmread(im_path).pixel_array\n",
    "\n",
    "    def rgba2ycbcr(self, img_rgba: np.ndarray) -> np.ndarray:\n",
    "        '''Takes an RBG image and returns it as a YCbCr image \n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        img_rgb : ndarray\n",
    "            The RGBA image which you want to convert to YCbCr\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        img_ycbcr : float ndarray\n",
    "            The converted image\n",
    "\n",
    "        '''\n",
    "        if len(img_rgba.shape) != 4:\n",
    "            raise ValueError('Input image is not RGBA')\n",
    "\n",
    "        img_rgb = img_rgba.astype(np.float32)\n",
    "        \n",
    "        img_ycrcb = cv2.cvtColor(img_rgba, cv2.COLOR_RGB2YCR_CB)\n",
    "        img_ycbcr = img_ycrcb[:,:,(0,2,1)].astype(np.float32)\n",
    "        img_ycbcr[:,:,0] = (img_ycbcr[:,:,0]*(235-16)+16)/255.0\n",
    "        img_ycbcr[:,:,1:] = (img_ycbcr[:,:,1:]*(240-16)+16)/255.0\n",
    "\n",
    "        return img_ycbcr\n",
    "\n",
    "    \n",
    "    def save_image(self, im: np.ndarray, fname: Path, verbose: bool = False) -> Path:\n",
    "        # Take a given image and save it as the specified format. The use of a Path variable type\n",
    "        # is intentional, as there should be less chance of incorrect entries\n",
    "        # fname = output name of the saved file, including the suffix\n",
    "        # im = numpy array of image\n",
    "        #\n",
    "        # returns fname, so it can be easily appended to a path if necessary\n",
    "\n",
    "        dim = im.shape #Get number of dimensions of image\n",
    "\n",
    "        if fname.suffix == '.png':\n",
    "            # Check that you aren't saving a 3D image\n",
    "            #TODO: Scale inputs to [0,255] so data isn't lost/image isn't saturated\n",
    "            cv2.imwrite(f'{fname}',im)\n",
    "            if verbose:\n",
    "                print(f'Saving: {fname}')\n",
    "        elif fname.suffix == '.nii' or fname.suffix == '.gz':\n",
    "\n",
    "            # TODO: Add option to transpose image for some reason because mricron hates the first dim[0] = 1\n",
    "            # Still gets loaded fine in terms of loading into python, but visualizing it is bad\n",
    "            # np.transpose(im, (1,2,0))\n",
    "\n",
    "\n",
    "            # TODO: If image is 2D then append a third  dimension before saving(?)\n",
    "            nib.save(nib.Nifti1Image(im, np.eye(len(dim)+1)), fname)\n",
    "            if verbose:\n",
    "                print(f'Saving: {fname}')\n",
    "        elif fname.suffix == '.dcm':\n",
    "            raise NotImplementedError('DICOM saving currently not supported')\n",
    "        else:\n",
    "            raise NotImplementedError(f'Specified file type {fname.suffix} for {fname} is currently not supported for saving')\n",
    "\n",
    "        return fname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ImgAug\n",
    "\n",
    "The idea behind the majority of these methods is that they intake a numpy array and some parameters and output a numpy array and string indicating what has changed.\n",
    "Is it better to assign the numpy array being worked on to an attribute of the class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import rotate, AffineTransform, warp, rescale, resize\n",
    "import math\n",
    "\n",
    "class ImgAug(ImgIE):\n",
    "    def __init__(self) -> None:\n",
    "        #super(ImgIE, self).__init__()\n",
    "        # super().__init__()\n",
    "        pass\n",
    "\n",
    "    # def aug_run(self, inp: np.ndarray, aug_key: \"OrderedDict[str, Any]\", randomize: bool=False) -> None:\n",
    "    #     '''Run provided augmentation using the settings defined by the template dictionary.\n",
    "    #     Possibly work storing the various methods into a dictionary\n",
    "    #     https://stackoverflow.com/questions/9168340/using-a-dictionary-to-select-function-to-execute\n",
    "\n",
    "    #     '''\n",
    "\n",
    "    #     function_key = {'translation': self.array_translate,\n",
    "    #     'rotation': self.array_rotate,\n",
    "    #     'scale': self.array_scale,\n",
    "    #     'patch': self.img2patches}\n",
    "\n",
    "\n",
    "    #     for func, kwrd in aug_key:\n",
    "    #         if func == 'translation':\n",
    "    #             inp, label = function_key[func](inp,**kwrd)\n",
    "    #         elif func == 'rotation':\n",
    "    #             inp, label = function_key[func](inp,**kwrd)\n",
    "    #         elif func == 'scale':\n",
    "    #             inp, label = function_key[func](inp,**kwrd)\n",
    "    #         elif func == 'patch':\n",
    "    #             inp, label,  = function_key[func](inp,**kwrd)\n",
    "    #     pass\n",
    "\n",
    "\n",
    "    def gen_random_aug(self, params: Dict[str,List[int]], float_params: bool=False, negative=True) -> Generator[Dict[str,List[int]],None, None]:\n",
    "        while True:\n",
    "            out_params = {}\n",
    "            if float_params:\n",
    "                for ky, i in params.items():\n",
    "                    out_params[ky] = [np.random.uniform(-k*negative, k) if k!=0 else k for k in i]\n",
    "            else:\n",
    "                for ky, i in params.items():\n",
    "                    out_params[ky] = [np.random.randint(-k*negative,k) if k!=0 else k for k in i]\n",
    "\n",
    "            yield out_params\n",
    "\n",
    "\n",
    "    def array_translate(self, im: np.ndarray, trans: List[int], mode: str='symmetric') -> \"tuple[np.ndarray, str]\":\n",
    "        # Translation\n",
    "        dim = im.shape\n",
    "\n",
    "        if len(dim) != len(trans):\n",
    "            raise IndexError(f'Translation of numpy array with dimensions: {dim} is not compatible with translation {trans}')\n",
    "        \n",
    "        if len(dim) == 2:\n",
    "            transform = AffineTransform(translation=(trans[0], trans[1]))\n",
    "            im = warp(im, transform, mode=mode)\n",
    "            label = f'_tr{trans[0]}_{trans[1]}'\n",
    "\n",
    "        elif len(trans) == 3:\n",
    "            transform = AffineTransform(translation=(trans[1], trans[2]))\n",
    "            for i in range(dim[0]):\n",
    "                im[i,:,:] = warp(im[i,:,:], transform, mode = mode)\n",
    "\n",
    "            for i in range(dim[1]):\n",
    "                # Because two dimensions were already translated, you only need to translate\n",
    "                # along one dimension\n",
    "                im[:,i,:] = warp(im[:,i,:], AffineTransform(translation=(trans[0],0)), mode='symmetric')\n",
    "                \n",
    "            label = f'_tr{trans[0]}_{trans[1]}_{trans[2]}'\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError(f\"Translation of objects with dimension {len(dim)} is not currently supported.\")\n",
    "        \n",
    "        return im, label\n",
    "\n",
    "\n",
    "    def array_rotate(self, im: np.ndarray, rot: List[int], order: int=1) -> \"tuple[np.ndarray, str]\":\n",
    "        # TODO: Issue with low resolution not necessairly having the same dimensions\n",
    "        # Rotation 2D\n",
    "        dim = im.shape\n",
    "\n",
    "        if len(dim) != len(rot):\n",
    "            raise IndexError(f'Translation of numpy array with dimensions: {dim} is not compatible with translation {rot}')\n",
    "\n",
    "        if len(dim) == 2:\n",
    "            im = rotate(im, rot[0], order=order)\n",
    "            label = f'_rot{rot[0]}'\n",
    "\n",
    "        # Rotation 3D\n",
    "        elif len(dim) == 3:\n",
    "            for i in range(dim[0]):\n",
    "                im[i,:,:] = rotate(im[i,:,:],rot[0], order=order)\n",
    "            for i in range(dim[1]):\n",
    "                im[:,i,:] = rotate(im[:,i,:],rot[1], order=order)\n",
    "            for i in range(dim[2]):\n",
    "                im[:,:,i] = rotate(im[:,:,i],rot[2], order=order)\n",
    "            label = f'_rot{rot[0]}_{rot[1]}_{rot[2]}'\n",
    "        \n",
    "        else:\n",
    "            raise NotImplementedError(f\"Translation of objects with dimension {len(rot)} is not currently supported.\")\n",
    "\n",
    "        return im, label\n",
    "\n",
    "    def array_scale(self, im: np.ndarray, scale: List[float], order: int=1, mode: str='symmetric', int_dims: bool=False) -> \"tuple[np.ndarray, str]\":\n",
    "        '''Either upscales or downscales provided array\n",
    "\n",
    "        https://scikit-image.org/docs/stable/auto_examples/transform/plot_rescale.html\n",
    "        '''\n",
    "        # Scaling\n",
    "        dim = im.shape\n",
    "\n",
    "        if len(dim) != len(scale):\n",
    "            raise IndexError(f'Scaling of numpy array with dimensions: {dim} is not compatible with translation {scale}')\n",
    "\n",
    "        if int_dims:\n",
    "            new_dims = scale\n",
    "            label = f'_si_'\n",
    "        else:\n",
    "            new_dims = [math.floor(x) for x in np.matmul(dim, scale)]\n",
    "            label = f'_sr_'\n",
    "\n",
    "        im = resize(im, new_dims, order=order, mode=mode) #If anti-alaising not specified, it is set to True when downsampling an image whose data type is not bool\n",
    "\n",
    "\n",
    "        if len(dim) == 2:\n",
    "            label = label + f'{scale[0]}_{scale[1]}'\n",
    "        elif len(dim) == 3:\n",
    "            label = label + f'{scale[0]}_{scale[1]}_{scale[2]}'\n",
    "        else:\n",
    "            raise NotImplementedError(f\"Translation of objects with dimension {len(scale)} is not currently supported.\")\n",
    "\n",
    "        return im, label\n",
    "        \n",
    "    def array_degrade(self, im: np.ndarray, scale: List[float], order: int=1, mode: str='symmetric', int_dims: bool=False) -> np.ndarray:\n",
    "        '''Uses array_scale to scale in array down and up using the specified order'''\n",
    "\n",
    "        dim = im.shape\n",
    "\n",
    "        im, _ = self.array_scale(im, scale, order=order, mode=mode, int_dims=int_dims)\n",
    "\n",
    "        im, _ = self.array_scale(im, dim, order=order, mode=mode, int_dims=True)\n",
    "\n",
    "        return im\n",
    "\n",
    "    \n",
    "    def gen_noise(self) -> None:\n",
    "        '''Add noise to provided image'''\n",
    "        pass\n",
    "    \n",
    "\n",
    "    def img2patches(self, im: np.ndarray, patch: List[int], step: List[int], fname:str, min_nonzero: float = 0,\n",
    "        slice_select: List[int] = [], save: List[str] = [], verbose=False) -> \"tuple[np.ndarray, List[str], List[int]]\":\n",
    "        # Depending on the number of dimenions in the `patch` value, either make 2D\n",
    "        # or 3D images\n",
    "\n",
    "        '''\n",
    "        Needs:\n",
    "            - image: tuple of numpy arrays? That way if you want to apply the same patching to multiple different images you can?\n",
    "            - min_nonzero: [float] either a flat value or a fraction of the minimum amount of input needs to be non-zero before you keep it\n",
    "            - slice_select: [list of ints] a list of slices to preserve from the patches (used when pairing slices between images)\n",
    "            - save_individual patches: tuple[path/filename, form] whether to save each of the patches as seperate files and what format to save them as.\n",
    "                                    if the tuple is empty, then just return the stack of patches and list of filenames \n",
    "            - verbose: [bool]\n",
    "            - patch; [list of ints] if they input -1 as a patch size, then take the full size of that dimension\n",
    "\n",
    "        Returns:\n",
    "            - image stack\n",
    "            - the paths to the image stack or file names for each of the images in the stack\n",
    "            - the slice_select list\n",
    "\n",
    "            not_blank: List[int] a list of all the entries in the stack that passed the min_nonzero quota\n",
    "        '''\n",
    "\n",
    "        # Check patch size\n",
    "        dim = im.shape\n",
    "\n",
    "        if len(dim) != len(patch):\n",
    "            raise IndexError(f'Patch selection of numpy array with dimensions: {dim} is not compatible with patch size: {patch}')\n",
    "\n",
    "        if len(dim) != len(step):\n",
    "            raise IndexError(f'Patch selection step size of numpy array with dimensions: {dim} is not compatible with step size: {step}')\n",
    "\n",
    "        # If they have input something for \"slice_select\", then they are trying to replicate patch selection\n",
    "        if len(slice_select):\n",
    "            min_nonzero = 0\n",
    "\n",
    "        for idx, i in enumerate(patch):\n",
    "            if i == -1:\n",
    "                patch[idx] = dim[idx]\n",
    "                step[idx] = 1\n",
    "        \n",
    "\n",
    "        # Create a numpy stack following Pytorch protocols, so 1 dimension more than patch\n",
    "        \n",
    "        # Count number of non-zero entries\n",
    "        cnt = 0\n",
    "        blank = 0\n",
    "        not_blank = []\n",
    "        itter = -1\n",
    "\n",
    "        # Get total number of patches that will be created:\n",
    "        #patch_count = np.prod([len(range(0,i,step[idx])) for idx, i in enumerate(dim)])\n",
    "        if verbose:\n",
    "            print(f'patch guess = {np.prod([math.floor((i-patch[idx])/step[idx])+1 for idx,i in enumerate(dim)])}')\n",
    "        patch_count = np.prod([math.floor((i-patch[idx])/step[idx])+1 for idx,i in enumerate(dim)])\n",
    "        \n",
    "        if min_nonzero > 1: #If they have given pixel/voxel numbers instead of fractions\n",
    "            patch_vol = math.prod(patch) - min_nonzero\n",
    "        else:\n",
    "            # else, calculate the number of pixels/voxels which must be nonzero\n",
    "            patch_vol = math.prod(patch) - math.prod(patch)*min_nonzero\n",
    "\n",
    "\n",
    "        #TODO: There MUST be a better way to organize this whole mess, lol\n",
    "        if len(dim) == 2:\n",
    "            stack = np.zeros((patch_count,patch[0],patch[1]))\n",
    "            if verbose:\n",
    "                print(f'stack size = {stack.shape}')\n",
    "\n",
    "            for i in range(0,dim[0],step[0]):\n",
    "                for j in range(0,dim[1],step[1]):\n",
    "                    if i+patch[0] <= dim[0] and j+patch[1] <= dim[1]:\n",
    "                        itter = itter+1 #just a calculator for finding when blanks occur\n",
    "                        samp = im[i:i+patch[0],j:j+patch[1]]\n",
    "\n",
    "                        if min_nonzero == 0 or (samp==0).sum() <= patch_vol:\n",
    "                            stack[cnt,:,:] = samp\n",
    "                            cnt += 1\n",
    "                            not_blank.append(itter)\n",
    "                        else:\n",
    "                            blank += 1\n",
    "    \n",
    "        elif len(dim) == 3:\n",
    "            stack = np.zeros((patch_count,patch[0],patch[1], patch[2]))\n",
    "            print(f'stack size = {stack.shape}')\n",
    "\n",
    "            for i in range(0,dim[0],step[0]):\n",
    "                for j in range(0,dim[1],step[1]):\n",
    "                    for k in range(0,dim[2],step[2]):\n",
    "                        #itter = itter+1 #just a calculator for finding when blanks occur\n",
    "                        if i+patch[0] <= dim[0] and j+patch[1] <= dim[1] and k+patch[2] <= dim[2]:\n",
    "                            itter = itter+1\n",
    "                            samp = im[i:i+patch[0],j:j+patch[1], k:k+patch[2]]\n",
    "\n",
    "                            if min_nonzero == 0 or (samp==0).sum() <= patch_vol:\n",
    "                                stack[cnt,:,:,:] = samp\n",
    "                                cnt += 1\n",
    "                                not_blank.append(itter)\n",
    "                            else:\n",
    "                                blank += 1\n",
    "        else:\n",
    "            raise IndexError(f'Images of dimension {dim} not supported by this method. Only 2D and 3D data accepted.')\n",
    "        \n",
    "\n",
    "        fnames = []\n",
    "        pnames = [] #Pnames should be used if patching is the last process you plan on doing. These are paths\n",
    "        if slice_select:\n",
    "            for i in range(len(slice_select)):\n",
    "                fnames.append(f'{save[0]}{fname}_{i}')\n",
    "        else:\n",
    "            for i in range(cnt):\n",
    "                fnames.append(f'{save[0]}{fname}_{i}')\n",
    "\n",
    "        if verbose:\n",
    "            print(f'Number of patches: {len(not_blank)}')\n",
    "            print(f'Number of blank patches: {blank}')\n",
    "\n",
    "\n",
    "        if save: #If they want to save the intermediate files (return a list of paths instead)\n",
    "            if slice_select:\n",
    "                for idx, i in enumerate(slice_select):\n",
    "                    pnames.append(self.save_image(stack[i], Path(fnames[idx]+save[1]), verbose=verbose))\n",
    "            else:\n",
    "                for idx, i in enumerate(fnames):\n",
    "                    pnames.append(self.save_image(stack[idx], Path(fnames[idx]+save[1]), verbose=verbose))\n",
    "\n",
    "            return np.array([]), pnames, not_blank # Send back not_blank for some comparison tests between running of this\n",
    "        \n",
    "        else:\n",
    "            if slice_select:\n",
    "                return stack[slice_select], fnames, [] #Only return the patches which match slice_select\n",
    "\n",
    "            else:\n",
    "                return stack[:cnt], fnames, not_blank  #Only return a stack of the patches that passed the min_nonzero check\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ImgDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImgDL(ImgAug):\n",
    "    def __init__(self) -> None:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ImgMet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImgMet():\n",
    "    '''Class for containing different performance metrics'''\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def PSNR_calc(self) -> float:\n",
    "        pass\n",
    "\n",
    "    def SSIR_calc(self) -> float:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U2Net Implementation\n",
    "This serves as a test-run for using this collection of classes on a real problemset.\n",
    "*Note: Task05 has two channels in its images*\n",
    "\n",
    "#### Outline for how to read in the unique file organization that U2Net has:\n",
    "The model requires the use of 3 different datasets, each kept in their own directory\n",
    "- Need to match both the original image and the label file together so they can be loaded at the same time\n",
    "    - Would be good to have a \"list of lists\" setup for this\n",
    "- Need to be able to select randomly from only one dataset at a time\n",
    "    - Ideally each epoch is from a different dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rough outline\n",
    "import shutil\n",
    "\n",
    "class UData(ImgAug):\n",
    "    '''Class for data management for U^2-Net training and testing\n",
    "    \n",
    "    Parameters\n",
    "    -------\n",
    "    - path pairs for the folders containing the raw images and the labels\n",
    "        [[/img_1, /label_1],[/img_2, /label_2]]\n",
    "    - output directory for generated images (after patches/augmentation is applied)\n",
    "\n",
    "    '''\n",
    "    def __init__(self, img_dir: str, label_dir: str, img_out_dir: str, label_out_dir: str, prefix: str='', suffix: str='') -> None:\n",
    "        self.img_dir = img_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.img_out_dir = img_out_dir\n",
    "        self.label_out_dir = label_out_dir\n",
    "        self.in_img_files, self.in_img_paths = self.get_files(img_dir, prefix, suffix)\n",
    "        self.in_label_files, self.in_label_paths = self.get_files(label_dir, prefix, suffix)\n",
    "        self.out_img_files = []\n",
    "        self.out_label_files = []\n",
    "\n",
    "\n",
    "    def get_files(self, file_dir:str, prefix:str, suffix:str) -> Tuple[List[str],List[str]]:\n",
    "        files = []\n",
    "        paths = []\n",
    "        # If they have provided a list of directories (in the case of DICOM or scattered data)\n",
    "        if isinstance(file_dir, list):\n",
    "            for inp_dir in file_dir:\n",
    "                for fil in os.listdir(inp_dir):\n",
    "                    if fil.startswith(prefix) and fil.endswith(suffix):\n",
    "                        paths.append(inp_dir + fil)\n",
    "                        files.append(fil)\n",
    "\n",
    "                    if not files:\n",
    "                        raise FileNotFoundError('No applicable files found in input directory')\n",
    "        else:\n",
    "            for fil in os.listdir(file_dir):\n",
    "                if fil.startswith(prefix) and fil.endswith(suffix):\n",
    "                    paths.append(file_dir + fil)\n",
    "                    files.append(fil)\n",
    "\n",
    "                if not files:\n",
    "                    raise FileNotFoundError('No applicable files found in input directory')\n",
    "\n",
    "        return files, paths\n",
    "\n",
    "    def match_files(self, img_dir: str, label_dir: str, update=False, paths=True) -> Tuple[List[Path], List[Path]]:\n",
    "        # Get the files that have been generated in the output directory\n",
    "        # If update is false, then just return a list of matched names, if true then\n",
    "        # change the class variable values accordingly.\n",
    "        hr_files = os.listdir(img_dir)\n",
    "        lr_files = os.listdir(label_dir)\n",
    "\n",
    "        # Get a set of all the files with agreement before the metadata\n",
    "        if len(hr_files) > len(lr_files):\n",
    "            matches = list(set(hr_files)-(set(hr_files)-set(lr_files)))\n",
    "        else:\n",
    "            matches = list(set(lr_files)-(set(lr_files)-set(hr_files)))\n",
    "\n",
    "        if update:\n",
    "            # If you want to save these matched files as class variables\n",
    "            self.out_img_files = [Path(img_dir + _) for _ in matches]\n",
    "            self.out_label_files = [Path(label_dir + _) for _ in matches]\n",
    "            print('Image and Lable file locations updated')\n",
    "        \n",
    "        if paths:\n",
    "            return [Path(img_dir + _) for _ in matches], [Path(label_dir + _ ) for _ in matches]\n",
    "        \n",
    "        return [], [] #lazy to make typing work out\n",
    "\n",
    "    def load_image_pair(self, im_id: Union[int, str] ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        # im_id can either be the index value or the name of the file\n",
    "        \n",
    "        if self.out_label_files:\n",
    "            if isinstance(im_id, int):\n",
    "                img_file = self.out_img_files[im_id]\n",
    "                label_file = self.out_label_files[im_id]\n",
    "            elif isinstance(im_id, str):\n",
    "                _ = self.out_img_files.index(Path(im_id))\n",
    "                img_file = self.out_img_files[_]\n",
    "                label_file = self.out_label_files[_]\n",
    "            else:\n",
    "                TypeError(\"Invalid image identifier, please input a string to integer\")\n",
    "\n",
    "            img = self.load_image(img_file)\n",
    "            lab = self.load_image(label_file)\n",
    "\n",
    "            return img, lab\n",
    "        else:\n",
    "            raise ValueError(\"No paths for processed image/label files are stored in this class\")\n",
    "\n",
    "\n",
    "    def run(self, clear=False, save=False, contain_lab: bool=False, verbose=False) -> None:\n",
    "        \n",
    "\n",
    "        if clear:\n",
    "            print('Clearing existing output directories')\n",
    "            shutil.rmtree(self.img_out_dir, ignore_errors=True)\n",
    "            shutil.rmtree(self.label_out_dir, ignore_errors=True)\n",
    "            \n",
    "\n",
    "        os.makedirs(self.img_out_dir, exist_ok=True)\n",
    "        os.makedirs(self.label_out_dir, exist_ok=True)\n",
    "        \n",
    "        fnames_h = []\n",
    "        fnames_l = []\n",
    "\n",
    "        # match in_image_files and in_label_files\n",
    "\n",
    "        #TODO: Come up with good way for match_files to handle multiple input directories\n",
    "        self.in_img_paths, self.in_label_paths = self.match_files(self.img_dir, self.label_dir, update=False, paths=True)\n",
    "\n",
    "        aug_params = {\"translation\":[10,10,10]}\n",
    "        patch = [50, 50, 1]\n",
    "        step = [20, 20, 2]\n",
    "\n",
    "        rand_params_gen = self.gen_random_aug(aug_params)\n",
    "\n",
    "        # for each image, label in in_img_files:\n",
    "        out_img_files = []\n",
    "        out_label_files = []\n",
    "\n",
    "        for im_p, lab_p in zip(self.in_img_paths, self.in_label_paths):\n",
    "\n",
    "            # generate a random parameter set\n",
    "            rand_params = next(rand_params_gen)\n",
    "\n",
    "            # Load images\n",
    "            im = self.load_image(im_p)\n",
    "            lab = self.load_image(lab_p)\n",
    "\n",
    "            # apply image augmentations to pairs of images\n",
    "            im, im_suf = self.array_translate(im, rand_params['translation'])\n",
    "            lab, lab_suf = self.array_translate(lab, rand_params['translation'])\n",
    "\n",
    "            # save as patches of size [x,y,z]\n",
    "            \n",
    "            if contain_lab: #Whether to only take patches which contain the label of interest\n",
    "\n",
    "                fname = lab_p.stem\n",
    "                _, b, not_lab = self.img2patches(lab, patch[:], step[:], min_nonzero= 0.3, fname=fname+lab_suf, save=[self.label_out_dir,'.nii'], verbose = False)\n",
    "                out_label_files.extend(b)\n",
    "\n",
    "                fname = im_p.stem\n",
    "                _, a, not_img = self.img2patches(im, patch[:], step[:], fname=fname+im_suf, slice_select=not_lab, save=[self.img_out_dir,'.nii'], verbose = False)\n",
    "                out_img_files.extend(a)\n",
    "\n",
    "            else:\n",
    "                fname = im_p.stem\n",
    "                _, a, not_img = self.img2patches(im, patch[:], step[:], fname=fname+im_suf, save=[self.img_out_dir,'.nii'], verbose = False)\n",
    "                out_img_files.extend(a)\n",
    "\n",
    "                fname = lab_p.stem\n",
    "                _, b, not_lab = self.img2patches(lab, patch[:], step[:], fname=fname+lab_suf, slice_select=not_img, save=[self.label_out_dir,'.nii'], verbose = False)\n",
    "                out_label_files.extend(b)\n",
    "            \n",
    "\n",
    "\n",
    "        # update file locations for use with load_image_pair\n",
    "        self.out_img_files = out_img_files\n",
    "        self.out_label_files = out_label_files\n",
    "        \n",
    "\n",
    "\n",
    "test = UData('../data/U2Net/Task02_Heart/imagesTr/','../data/U2Net/Task02_Heart/labelsTr/','../data/U2Net/Task02_Heart/IMG_Patch/','../data/U2Net/Task02_Heart/Label_Patch/')\n",
    "\n",
    "test.run(clear=True, save=True, contain_lab=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50, 1)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.load_image_pair(1)[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SrGen recreation\n",
    "Using the defined classes above, is it possible to recreate the SrGen class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "class SrGen(ImgAug):\n",
    "    def __init__(self, inp_dir, HR_out_dir, LR_out_dir, prefix='', suffix='') -> None:\n",
    "        self.inp_dir = inp_dir\n",
    "        self.HR_out_dir = HR_out_dir\n",
    "        self.HR_files = None\n",
    "        self.LR_out_dir = LR_out_dir\n",
    "        self.LR_files = None\n",
    "        self.inp_files, self.inp_paths = self._get_inp_(prefix, suffix)\n",
    "\n",
    "    def _get_inp_(self, prefix='', suffix='')->Tuple[List[str],List[str]]:\n",
    "\n",
    "        files = []\n",
    "        paths = []\n",
    "        # If they have provided a list of directories (in the case of DICOM or scattered data)\n",
    "        if isinstance(self.inp_dir, list):\n",
    "            for inp_dir in self.inp_dir:\n",
    "                for fil in os.listdir(inp_dir):\n",
    "                    if fil.startswith(prefix) and fil.endswith(suffix):\n",
    "                        paths.append(inp_dir + fil)\n",
    "                        files.append(fil)\n",
    "\n",
    "                    if not files:\n",
    "                        raise FileNotFoundError('No applicable files found in input directory')\n",
    "        else:\n",
    "            for fil in os.listdir(self.inp_dir):\n",
    "                if fil.startswith(prefix) and fil.endswith(suffix):\n",
    "                    paths.append(self.inp_dir + fil)\n",
    "                    files.append(fil)\n",
    "\n",
    "                if not files:\n",
    "                    raise FileNotFoundError('No applicable files found in input directory')\n",
    "\n",
    "        return files, paths\n",
    "    \n",
    "    def _get_LR_out_(self) -> List[str]:\n",
    "        # get list of files in output directory and determine matching files\n",
    "        return os.listdir(self.LR_out_dir)\n",
    "\n",
    "    def _get_HR_out_(self) -> List[str]:\n",
    "        return os.listdir(self.HR_out_dir)\n",
    "\n",
    "    def match_altered(self, update=True, paths=False, sort=False):\n",
    "        # Get the files that have been generated in the output directory\n",
    "        # If update is false, then just return a list of matched names, if true then\n",
    "        # change the class variable values accordingly.\n",
    "        hr_files = self._get_HR_out_()\n",
    "        lr_files = self._get_LR_out_()\n",
    "\n",
    "        # Get a set of all the files with agreement before the metadata\n",
    "        if len(hr_files) > len(lr_files):\n",
    "            if sort: #TODO: make sort so it isnt [*1.*, *10.*, *100.*, ..., *2.*,...]\n",
    "                matches = sorted(list(set(hr_files)-(set(hr_files)-set(lr_files))))\n",
    "            else:\n",
    "                matches = list(set(hr_files)-(set(hr_files)-set(lr_files)))\n",
    "        else:\n",
    "            if sort:\n",
    "                matches = sorted(list(set(lr_files)-(set(lr_files)-set(hr_files))))\n",
    "            else:\n",
    "                matches = list(set(lr_files)-(set(lr_files)-set(hr_files)))\n",
    "\n",
    "        if update:\n",
    "            # If you want to save these matched files as class variables\n",
    "            self.HR_files = [self.HR_out_dir + _ for _ in matches]\n",
    "            self.LR_files = [self.LR_out_dir + _ for _ in matches]\n",
    "            print('HR and LR file locations updated')\n",
    "        \n",
    "        if paths:\n",
    "            return self.HR_files, self.LR_files\n",
    "        \n",
    "    def change_out(self, HR_out_dir, LR_out_dir):\n",
    "        # Change the output locations so you can save into a new file\n",
    "        self.HR_out_dir = HR_out_dir\n",
    "        self.HR_files = None\n",
    "        self.LR_out_dir = LR_out_dir\n",
    "        self.LR_files = None\n",
    "\n",
    "\n",
    "    def run(self, clear=False, save=False, verbose=False):\n",
    "        # This method is called to generate the data\n",
    "\n",
    "        if clear:\n",
    "            print('Clearing existing output directories')\n",
    "            shutil.rmtree(self.HR_out_dir, ignore_errors=True)\n",
    "            if self.template['resolution'] != None:\n",
    "                shutil.rmtree(self.LR_out_dir, ignore_errors=True)\n",
    "                os.makedirs(self.LR_out_dir, exist_ok=True)\n",
    "\n",
    "        os.makedirs(self.HR_out_dir, exist_ok=True)\n",
    "        fnames_h = []\n",
    "        fnames_l = []\n",
    "\n",
    "        for ids, im in enumerate(self.inp_paths):\n",
    "            im_h = self.load_image(im, verbose)\n",
    "            opp, im_h = self.img_transform(im_h)\n",
    "\n",
    "            # Prevents weird new file naming issues when input is compressed file (.nii.gz)\n",
    "            im = Path(im)\n",
    "            while im.suffix in {'.tar', '.gz', '.zip'}:\n",
    "                im = im.with_suffix('')\n",
    "            \n",
    "            im = os.path.splitext(im)[0]+opp # Add transformations to file name\n",
    "            im = os.path.split(im)[1]\n",
    "        \n",
    "            # Generate Low Resolution\n",
    "            if self.template['resolution']:\n",
    "\n",
    "                dim = im_h.shape\n",
    "                # efficient way to either make a single value into an array or do nothing if resolution is already a vector\n",
    "                # TODO: replace transformation if statements with this\n",
    "                self.template['resolution'] = [int(x) for x in np.multiply(np.ones(len(dim)), self.template['resolution'])]\n",
    "\n",
    "                # Check that dimensions of HR image are multiples of resolution change, else shave off data\n",
    "                for i in range(len(dim)):\n",
    "                    if dim[i] % self.template['resolution'][i]:\n",
    "                        # If it isn't a clean scaling down\n",
    "                        _ = dim[i]-(dim[i] % self.template['resolution'][i])\n",
    "\n",
    "                        im_h = np.delete(im_h,[x for x in range(_, dim[i])],i)\n",
    "\n",
    "                im_l = self.gen_LR_img(im_h, self.template['resolution'])\n",
    "\n",
    "            # Create image patches and save them\n",
    "            if self.template['patch'] and save:\n",
    "                fnames_h, slice_select = self.img2patches(im_h, self.HR_out_dir + im, save=True, sanity_check=True)\n",
    "                if self.template['resolution'] != None:\n",
    "                    fnames_l = self.img2patches(im_l, self.LR_out_dir + im, same_size=self.template['same_size'], save=True, slice_select=slice_select, sanity_check=False)\n",
    "\n",
    "                    # if not _a == _:\n",
    "                    #     raise FileExistsError('''WARNING: The patches for High and Low resolution do not match, this is\n",
    "                    #         most likely due to resolution scaling or patches/steps not being divisible by resolution''')\n",
    "\n",
    "            elif save:\n",
    "                fname_h = f'{self.HR_out_dir}{im}.{self.template[\"out_type\"]}'\n",
    "                self.save_image(fname_h, im_h, verbose)\n",
    "                fnames_h.append(fname_h)\n",
    "                if self.template['resolution']:# != None:\n",
    "                    fname_l = f'{self.LR_out_dir}{im}.{self.template[\"out_type\"]}'\n",
    "                    self.save_image(fname_l, im_l, verbose)\n",
    "                    fnames_l.append(fname_l)\n",
    "\n",
    "\n",
    "        self.HR_files = fnames_h\n",
    "        self.LR_files = fnames_l\n",
    "\n",
    "        print('Files processed successfully')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit ('3.8.7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "539b544e2c3fdc58492248d082a132f5e0b4fea63e914fb274c32873997cf2f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
