{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D U^2-Net: A 3D Universal U-Net for Multi-Domain Medical Image Segmentation:\n",
    "Test things here\n",
    "https://theaisummer.com/unet-architectures/\n",
    "\n",
    "https://github.com/patrick-kidger/torchtyping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "The Medical Segmentation Decathalon data is assumed to be provided in a particular organizational structure with respect to this folder. For the sake of this exercise, I only will be using three of the provided datasets. If you have these files in the correct folder, you should receive the same (or similar) results.\n",
    "\n",
    "```\n",
    "../data/U2Net/\n",
    "        Task02_Heart/\n",
    "            imagesTr/\n",
    "                la_003.nii.gz\n",
    "                ...\n",
    "                la_030.nii.gz\n",
    "            imagesTs/\n",
    "                la_001.nii.gz\n",
    "                ...\n",
    "                la_028.nii.gz\n",
    "            labelsTr/\n",
    "                la_003.nii.gz\n",
    "                ...\n",
    "                la_030.nii.gz\n",
    "        \n",
    "        Task04_Hippocampus/\n",
    "            imagesTr/\n",
    "                hippocampus_001.nii.gz\n",
    "                ...\n",
    "                hippocampus_394.nii.gz\n",
    "            imagesTs/\n",
    "                hippocampus_002.nii.gz\n",
    "                ...\n",
    "                hippocampus_392.nii.gz\n",
    "            labelsTr/\n",
    "                hippocampus_001.nii.gz\n",
    "                ...\n",
    "                hippocampus_394.nii.gz\n",
    "\n",
    "        Task05_Prostate/\n",
    "            imagesTr/\n",
    "                prostate_00.nii.gz\n",
    "                ...\n",
    "                prostate_47.nii.gz\n",
    "            imagesTs/\n",
    "                prostate_03.nii.gz\n",
    "                ...\n",
    "                prostate_45.nii.gz\n",
    "            labelsTr/\n",
    "                prostate_00.nii.gz\n",
    "                ...\n",
    "                prostate_47.nii.gz\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "Like any good Jupyter notebook, we start with importing all the different functions and modules we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "sys.path.append('..') # Stupid thing Python makes you do to import from a sibling directory\n",
    "from gen_utils.ImgTools import ImgAug # Custom class for image generation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image creation class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Iterable, Tuple, Any, Union, Generator, Dict\n",
    "from pathlib import Path\n",
    "\n",
    "class UData(ImgAug):\n",
    "    '''Class for data management for U^2-Net training and testing\n",
    "    \n",
    "    Parameters\n",
    "    -------\n",
    "    - path pairs for the folders containing the raw images and the labels\n",
    "        [[/img_1, /label_1],[/img_2, /label_2]]\n",
    "    - output directory for generated images (after patches/augmentation is applied)\n",
    "\n",
    "    '''\n",
    "    def __init__(self, img_dir: str, label_dir: str, img_out_dir: str, label_out_dir: str, prefix: str='', suffix: str='') -> None:\n",
    "        self.img_dir = img_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.img_out_dir = img_out_dir\n",
    "        self.label_out_dir = label_out_dir\n",
    "        self.in_img_files, self.in_img_paths = self.get_files(img_dir, prefix, suffix)\n",
    "        self.in_label_files, self.in_label_paths = self.get_files(label_dir, prefix, suffix)\n",
    "        self.out_img_files = []\n",
    "        self.out_label_files = []\n",
    "\n",
    "\n",
    "    def get_files(self, file_dir:str, prefix:str, suffix:str) -> Tuple[List[str],List[str]]:\n",
    "        files = []\n",
    "        paths = []\n",
    "        # If they have provided a list of directories (in the case of DICOM or scattered data)\n",
    "        if isinstance(file_dir, list):\n",
    "            for inp_dir in file_dir:\n",
    "                for fil in os.listdir(inp_dir):\n",
    "                    if fil.startswith(prefix) and fil.endswith(suffix):\n",
    "                        paths.append(inp_dir + fil)\n",
    "                        files.append(fil)\n",
    "\n",
    "                    if not files:\n",
    "                        raise FileNotFoundError('No applicable files found in input directory')\n",
    "        else:\n",
    "            for fil in os.listdir(file_dir):\n",
    "                if fil.startswith(prefix) and fil.endswith(suffix):\n",
    "                    paths.append(file_dir + fil)\n",
    "                    files.append(fil)\n",
    "\n",
    "                if not files:\n",
    "                    raise FileNotFoundError('No applicable files found in input directory')\n",
    "\n",
    "        return files, paths\n",
    "\n",
    "    def match_files(self, img_dir: str, label_dir: str, update=False, paths=True) -> Tuple[List[Path], List[Path]]:\n",
    "        # Get the files that have been generated in the output directory\n",
    "        # If update is false, then just return a list of matched names, if true then\n",
    "        # change the class variable values accordingly.\n",
    "        hr_files = os.listdir(img_dir)\n",
    "        lr_files = os.listdir(label_dir)\n",
    "\n",
    "        # Get a set of all the files with agreement before the metadata\n",
    "        if len(hr_files) > len(lr_files):\n",
    "            matches = list(set(hr_files)-(set(hr_files)-set(lr_files)))\n",
    "        else:\n",
    "            matches = list(set(lr_files)-(set(lr_files)-set(hr_files)))\n",
    "\n",
    "        if update:\n",
    "            # If you want to save these matched files as class variables\n",
    "            self.out_img_files = [Path(img_dir + _) for _ in matches]\n",
    "            self.out_label_files = [Path(label_dir + _) for _ in matches]\n",
    "            print('Image and Lable file locations updated')\n",
    "        \n",
    "        if paths:\n",
    "            return [Path(img_dir + _) for _ in matches], [Path(label_dir + _ ) for _ in matches]\n",
    "        \n",
    "        return [], [] #lazy to make typing work out\n",
    "\n",
    "    def load_image_pair(self, im_id: Union[int, str] ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        # im_id can either be the index value or the name of the file\n",
    "        \n",
    "        if self.out_label_files:\n",
    "            if isinstance(im_id, int):\n",
    "                img_file = self.out_img_files[im_id]\n",
    "                label_file = self.out_label_files[im_id]\n",
    "            elif isinstance(im_id, str):\n",
    "                _ = self.out_img_files.index(Path(im_id))\n",
    "                img_file = self.out_img_files[_]\n",
    "                label_file = self.out_label_files[_]\n",
    "            else:\n",
    "                TypeError(\"Invalid image identifier, please input a string to integer\")\n",
    "\n",
    "            img = self.load_image(img_file)\n",
    "            lab = self.load_image(label_file)\n",
    "\n",
    "            return img, lab\n",
    "        else:\n",
    "            raise ValueError(\"No paths for processed image/label files are stored in this class\")\n",
    "\n",
    "\n",
    "    def run(self, clear=False, save=False, contain_lab: bool=False, verbose=False) -> None:\n",
    "        \n",
    "\n",
    "        if clear:\n",
    "            print('Clearing existing output directories')\n",
    "            shutil.rmtree(self.img_out_dir, ignore_errors=True)\n",
    "            shutil.rmtree(self.label_out_dir, ignore_errors=True)\n",
    "            \n",
    "\n",
    "        os.makedirs(self.img_out_dir, exist_ok=True)\n",
    "        os.makedirs(self.label_out_dir, exist_ok=True)\n",
    "        \n",
    "        fnames_h = []\n",
    "        fnames_l = []\n",
    "\n",
    "        # match in_image_files and in_label_files\n",
    "\n",
    "        #TODO: Come up with good way for match_files to handle multiple input directories\n",
    "        self.in_img_paths, self.in_label_paths = self.match_files(self.img_dir, self.label_dir, update=False, paths=True)\n",
    "\n",
    "        aug_params = {\"translation\":[10,10,10]}\n",
    "        patch = [64, 64, 64] #Remember these have to be able to be divided down and back by 2...\n",
    "        step = [20, 20, 20]\n",
    "\n",
    "        rand_params_gen = self.gen_random_aug(aug_params)\n",
    "\n",
    "        # for each image, label in in_img_files:\n",
    "        out_img_files = []\n",
    "        out_label_files = []\n",
    "\n",
    "        for im_p, lab_p in zip(self.in_img_paths, self.in_label_paths):\n",
    "\n",
    "            # generate a random parameter set\n",
    "            rand_params = next(rand_params_gen)\n",
    "\n",
    "            # Load images\n",
    "            im = self.load_image(im_p)\n",
    "            lab = self.load_image(lab_p)\n",
    "\n",
    "            # apply image augmentations to pairs of images\n",
    "            im, im_suf = self.array_translate(im, rand_params['translation'])\n",
    "            lab, lab_suf = self.array_translate(lab, rand_params['translation'])\n",
    "\n",
    "            # save as patches of size [x,y,z]\n",
    "            \n",
    "            if contain_lab: #Whether to only take patches which contain the label of interest\n",
    "\n",
    "                fname = lab_p.stem\n",
    "                _, b, not_lab = self.img2patches(lab, patch[:], step[:], min_nonzero= 0.1, fname=fname+lab_suf, save=[self.label_out_dir,'.nii'], verbose = False)\n",
    "                out_label_files.extend(b)\n",
    "\n",
    "                fname = im_p.stem\n",
    "                _, a, not_img = self.img2patches(im, patch[:], step[:], fname=fname+im_suf, slice_select=not_lab, save=[self.img_out_dir,'.nii'], verbose = False)\n",
    "                out_img_files.extend(a)\n",
    "\n",
    "            else:\n",
    "                fname = im_p.stem\n",
    "                _, a, not_img = self.img2patches(im, patch[:], step[:], fname=fname+im_suf, save=[self.img_out_dir,'.nii'], verbose = False)\n",
    "                out_img_files.extend(a)\n",
    "\n",
    "                fname = lab_p.stem\n",
    "                _, b, not_lab = self.img2patches(lab, patch[:], step[:], fname=fname+lab_suf, slice_select=not_img, save=[self.label_out_dir,'.nii'], verbose = False)\n",
    "                out_label_files.extend(b)\n",
    "            \n",
    "\n",
    "\n",
    "        # update file locations for use with load_image_pair\n",
    "        self.out_img_files = out_img_files\n",
    "        self.out_label_files = out_label_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proposed U^2-Net:\n",
    "Adapter types:\n",
    "\n",
    "`'series_adapter'` = Series Residual Adapter\n",
    "\n",
    "`'parallel_adapter'` = Parallel Residual Adapter\n",
    "\n",
    "`'separable_adapter'` = Residual Adapter which incorporates depthwise separable convolution (what the paper is proposing)\n",
    "\n",
    "Model types:\n",
    "\n",
    "`'universal'` = Model proposed in manuscript that maintains pointwise convoltion parameters across domains while having domain-specific depthwise convolution\n",
    "\n",
    "`'independent'` = Generic U-Net model trained on single image domain\n",
    "\n",
    "`'shared'` = Generic U-Net trained on combinaiton of all image domains(?)\n",
    "\n",
    "- All model types seem to use some sort of [residual adapter](https://www.researchgate.net/figure/Series-vs-parallel-residual-adapters-a-typical-module-of-a-residual-network-inclusive_fig1_324055530) inspired by this [repository](https://github.com/srebuffi/residual_adapters/)\n",
    "\n",
    "\n",
    "Original code key:\n",
    "`nb_tasks` = The number of unique tasks that you are using the model for. So if there are two different image sets you want different models for, then `nb_tasks` = 2\n",
    "\n",
    "`config.module` = the type of adapter you wish to use\n",
    "\n",
    "`config.trainMode` = the model type you wish to use\n",
    "\n",
    "`config.task_idx` = the id number associated with a particular task, this allows for selecting the weights by index for a particular task. So in `q = nn.ModuleList(...)` if you want to use the weights associated with task `i` you use `q[i](input)`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U2-Net steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_pool2stride_size(num_pool_per_axis):\n",
    "    '''\n",
    "    Calculate the stride size for the max pooling which occurs, If the num_pool_per_axis[i] for axis 2 is less than the maximum, then\n",
    "    instead of a 2x2x2 pooling it will be a 2x1x2 pooling. With a step size of 1 along the axis, the pooling will not downsample it\n",
    "\n",
    "    \"The number of down-sampling operations per axis is set until the feature map size of the deepest layer reaches as small as 8\"\n",
    "    '''\n",
    "    max_num = max(num_pool_per_axis)\n",
    "    stride_size_per_pool = list()\n",
    "    for i in range(max_num):\n",
    "        unit = [1,2]\n",
    "        stride_size_per_pool.append([unit[i<num_pool_per_axis[0]], unit[i<num_pool_per_axis[1]], unit[i<num_pool_per_axis[2]]])\n",
    "    return stride_size_per_pool\n",
    "\n",
    "\n",
    "class U2Net3D(nn.Module):\n",
    "    def __init__(self, inChans_list: 'List[int]', num_pool_per_axis: 'List[int]', base_outChans: int=16, num_class_list: 'List[int]'=[4],\n",
    "        trainMode: str='universal', module: str='separable_adapter', deep_supervision: bool=True) -> None:\n",
    "        '''\n",
    "        Parameters:\n",
    "        inChans_list: list of input channels for the differnet image types you will be using\n",
    "        num_pool_per_axis: the number of times you wish for this axis to be downsampled by 2x2 max pooling in the endocer portion.\n",
    "                If you have a U-Net with depth 5 but only want to downsample the x-axis 3 times, then you would put [3,5,5]\n",
    "        base_out_Chans: number of output channels for the input image before it goes through the U^2-Net\n",
    "        num_class_list: \n",
    "        depth: the depth of the U-Net\n",
    "        trainMode: The U-Net model type being used\n",
    "        module: The type of adapter you want to use\n",
    "        deep_supervision: whether to apply deep_supervision\n",
    "        '''\n",
    "\n",
    "        super(U2Net3D, self).__init__()\n",
    "        #trainMode = the model type being used\n",
    "        self.trainMode = trainMode\n",
    "        self.module = module\n",
    "        self.deep_supervision = deep_supervision\n",
    "\n",
    "        nb_tasks = len(num_class_list)\n",
    "\n",
    "        self.depth = max(num_pool_per_axis) + 1 # config.num_pool_per_axis firstly defined in train_xxxx.py or main.py\n",
    "        stride_sizes = num_pool2stride_size(num_pool_per_axis)\n",
    "\n",
    "        # Create a module list of the InputTransitions for each input data type\n",
    "        # In other words, if you are running this model on a set of images with 2 channels and a set of\n",
    "        # images with 3 channels, then self.in_tr_list = nn.ModuleList([[2x InputTran],[3x InputTran]])\n",
    "        \n",
    "        # TODO: In this implementaiton, they are applying a 3x3x3 instead of a 1x1x1 like they say in the paper \n",
    "        self.in_tr_list = nn.ModuleList(\n",
    "            [InputTransition(inChans_list[j], base_outChans) for j in range(nb_tasks)]\n",
    "        )\n",
    "\n",
    "        outChans_list = list()\n",
    "        self.down_blocks = nn.ModuleList() #register modules from regular python list.\n",
    "        self.down_samps = nn.ModuleList()\n",
    "        self.down_pads = list() # used to pad as padding='same' in tensorflow\n",
    "\n",
    "        inChans = base_outChans\n",
    "\n",
    "        # Create each level of the encoder and decoder\n",
    "        for i in range(self.depth):\n",
    "            outChans = base_outChans * (2**i)\n",
    "            outChans_list.append(outChans)\n",
    "\n",
    "            # Add another encoder level to the down_block module list\n",
    "            self.down_blocks.append(DownBlock(nb_tasks, inChans, outChans, trainMode, module, kernel_size=3, stride=1, padding=1))\n",
    "\n",
    "            if i != self.depth-1:\n",
    "                # stride for each axis could be 1 or 2, depending on tasks. # to apply padding='SAME' as tensorflow, cal and save pad num to manually pad in forward().\n",
    "                pads = list() # 6 elements for one 3-D volume. originized for last dim backward to first dim, e.g. w,w,h,h,d,d # required for F.pad.\n",
    "                # pad 1 to the right end if s=2 else pad 1 to both ends (s=1). \n",
    "                for j in stride_sizes[i][::-1]:\n",
    "                    if j == 2:\n",
    "                        pads.extend([0,1])\n",
    "                    elif j == 1:\n",
    "                        pads.extend([1,1])\n",
    "                self.down_pads.append(pads) \n",
    "                self.down_samps.append(DownSample(nb_tasks, outChans, outChans*2, trainMode, module, kernel_size=3, stride=tuple(stride_sizes[i]), padding=0))\n",
    "                inChans = outChans*2\n",
    "            else:\n",
    "                inChans = outChans\n",
    "\n",
    "        ## END OF ENCODING\n",
    "        ## BEGINNING OF DECODING\n",
    "\n",
    "        # TODO: Feel like there is a better way to do this...    \n",
    "        self.up_blocks = nn.ModuleList([None] * (self.depth-1))\n",
    "        self.up_samps = nn.ModuleList([None] * (self.depth-1))\n",
    "        self.dSupers = nn.ModuleList()\n",
    "\n",
    "\n",
    "        for i in range(self.depth-2, -1, -1):\n",
    "            #Set up the upsampling which corresponds to the downsampling\n",
    "            self.up_samps[i] = UnetUpsample(nb_tasks, inChans, outChans_list[i], trainMode, module, up_stride=stride_sizes[i])\n",
    "            self.up_blocks[i] = UpBlock(nb_tasks, outChans_list[i]*2, outChans_list[i], trainMode, module, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "            if self.deep_supervision and i < 3 and i > 0:\n",
    "                self.dSupers.append(nn.ModuleList(\n",
    "                    [DeepSupervision(outChans_list[i], num_class_list[j], up_stride=tuple(stride_sizes[i-1])) for j in range(nb_tasks)]\n",
    "                ))\n",
    "\n",
    "            inChans = outChans_list[i]\n",
    "\n",
    "        self.out_tr_list = nn.ModuleList(\n",
    "            [OutputTransition(inChans, num_class_list[j]) for j in range(nb_tasks)]\n",
    "        )\n",
    "\n",
    "    def forward(self, x:torch.Tensor, task_idx: int=0) -> torch.Tensor:\n",
    "        \n",
    "        deep_supervision = None #Mking this None is intentional (doesn't deactivate it)\n",
    "\n",
    "        out = self.in_tr_list[task_idx](x)\n",
    "\n",
    "        down_list = list()\n",
    "        for i in range(self.depth):\n",
    "            out = self.down_blocks[i](out, task_idx)\n",
    "            # down_list.append(out)\n",
    "            if i != self.depth-1:\n",
    "                # print(f'shape of out is : {out.shape}')\n",
    "                down_list.append(out) # will not store the deepest, so as to save memory\n",
    "                out = F.pad(out,tuple(self.down_pads[i]), mode=\"constant\", value=0)\n",
    "                out = self.down_samps[i](out, task_idx)\n",
    "        \n",
    "\n",
    "        idx = 0\n",
    "        for i in range(self.depth-2, -1, -1):\n",
    "            if self.module in ['parallel_adapter', 'separable_adapter']:\n",
    "                out, share_map, para_map = self.up_samps[i](out, task_idx)\n",
    "            else:\n",
    "                out = self.up_samps[i](out, task_idx)\n",
    "\n",
    "            up_x = out\n",
    "            out = torch.cat((out, down_list[i]), dim=1) #concatenate across channels?\n",
    "            out = self.up_blocks[i](out, task_idx) #TODO: check what up_x used to be, because they also removed it, up_x)\n",
    "\n",
    "            if self.deep_supervision and i < 3 and i > 0:\n",
    "                deep_supervision = self.dSupers[idx][task_idx](out, deep_supervision)\n",
    "                idx += 1\n",
    "        \n",
    "        out = self.out_tr_list[task_idx](out, deep_supervision)\n",
    "\n",
    "        if self.module in ['parallel_adapter', 'separable_adapter']:\n",
    "            return out, share_map, para_map\n",
    "\n",
    "        else:\n",
    "            return out\n",
    "\n",
    "\n",
    "class DownSample(nn.Module):\n",
    "    # TODO: DownSampling is not 2x2 MaxPooling, but simply a convolution with a \n",
    "    def __init__(self, nb_tasks, inChans, outChans, trainMode, module, kernel_size=3, stride=1, padding=1) -> None:\n",
    "        super(DownSample, self).__init__()\n",
    "        self.op1 = conv_unit(nb_tasks, inChans, outChans, trainMode, module, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "        self.act1 = norm_act(outChans, meth=\"act\")\n",
    "\n",
    "    def forward(self, x, task_idx: int) -> torch.Tensor:\n",
    "        out = self.op1(x, task_idx)\n",
    "        out = self.act1(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class DownBlock(nn.Module):\n",
    "    def __init__(self, nb_tasks, inChans, outChans, trainMode, module: str='separable_adapter', residual: bool=True, kernel_size=3, stride=1, padding=1) -> None:\n",
    "        super(DownBlock, self).__init__()\n",
    "        self.module = module\n",
    "        self.residual = residual\n",
    "        self.op1 = conv_unit(nb_tasks, inChans, outChans, trainMode, module, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "        self.act1 = norm_act(outChans, meth=\"act\")\n",
    "        self.op2 = conv_unit(nb_tasks, outChans, outChans, trainMode, module, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "        self.act2 = norm_act(outChans, meth=\"act\")\n",
    "\n",
    "    def forward(self, x, task_idx: int)-> torch.Tensor:\n",
    "\n",
    "        # TODO: These if/else statements are redundant...\n",
    "\n",
    "        if self.module == 'parallel_adapter' or self.module == 'separable_adapter':\n",
    "            out, share_map, para_map = self.op1(x, task_idx)\n",
    "        else:\n",
    "            out = self.op1(x, task_idx)\n",
    "        out = self.act1(out)\n",
    "        if self.module == 'parallel_adapter' or self.module == 'separable_adapter':\n",
    "            out, share_map, para_map = self.op2(out, task_idx)\n",
    "        else:\n",
    "            out = self.op2(out, task_idx)\n",
    "        if self.residual: # same to ResNet\n",
    "            out = self.act2(x + out)\n",
    "        else:\n",
    "            out = self.act2(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class UnetUpsample(nn.Module):\n",
    "    def __init__(self, nb_tasks, inChans, outChans,trainMode, module, up_stride=(2,2,2)):\n",
    "        super(UnetUpsample, self).__init__()\n",
    "        self.module = module\n",
    "        self.upsamples = nn.ModuleList(\n",
    "            [Upsample3D(scale_factor=up_stride) for i in range(nb_tasks)]\n",
    "        )\n",
    "        self.op = conv_unit(nb_tasks, inChans, outChans, trainMode, module, kernel_size=3,stride=1, padding=1)\n",
    "        self.act = norm_act(outChans, meth='act')\n",
    "\n",
    "    def forward(self, x, task_idx: int):\n",
    "        out = self.upsamples[task_idx](x)\n",
    "        if self.module == 'parallel_adapter' or self.module == 'separable_adapter':\n",
    "            out, share_map, para_map = self.op(out, task_idx)\n",
    "        else:\n",
    "            out = self.op(out, task_idx)\n",
    "        out = self.act(out)\n",
    "        if self.module == 'parallel_adapter' or self.module == 'separable_adapter':\n",
    "            return out, share_map, para_map\n",
    "        else:\n",
    "            return out\n",
    "\n",
    "\n",
    "def Upsample3D(scale_factor=(2.0,2.0,2.0)):\n",
    "    '''\n",
    "    task specific\n",
    "    '''\n",
    "    # l = tf.keras.layers.UpSampling3D(size=up_strides, data_format=DATA_FORMAT)(l) # by tkuanlun350. # no equavalent in torch?\n",
    "    # scale_factor can also be a tuple. so able to custom scale_factor for each dim.\n",
    "    scale_factor = [float(i) for i in scale_factor] # nn.Upsample wants float values, not integers\n",
    "    upsample = nn.Upsample(scale_factor=tuple(scale_factor), mode='nearest') # ignore the warnings. Only module like upsample can be shown in my visualization. # if using ConvTranspose3d, be careful to how to pad when the down sample method used padding='SAME' strategy.\n",
    "    return upsample\n",
    "\n",
    "class UpBlock(nn.Module):\n",
    "    def __init__(self, nb_tasks, inChans, outChans, trainMode, module: str='separable_adapter', kernel_size=3, stride=1, padding=1):\n",
    "        super(UpBlock, self).__init__()\n",
    "        self.module = module\n",
    "        self.op1 = conv_unit(nb_tasks, inChans, outChans, trainMode, module, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "        self.act1 = norm_act(outChans, meth=\"act\")\n",
    "        self.op2 = conv_unit(nb_tasks, outChans, outChans, trainMode, module, kernel_size=1, stride=1, padding=0)\n",
    "        self.act2 = norm_act(outChans, meth=\"act\")\n",
    "\n",
    "    def forward(self, x, task_idx: int):\n",
    "        if self.module == 'parallel_adapter' or self.module == 'separable_adapter':\n",
    "            out, share_map, para_map = self.op1(x, task_idx)\n",
    "        else:\n",
    "            out = self.op1(x, task_idx)\n",
    "        out = self.act1(out)\n",
    "        if self.module == 'parallel_adapter' or self.module == 'separable_adapter':\n",
    "            out, share_map, para_map = self.op2(out, task_idx)\n",
    "        else:\n",
    "            out = self.op2(out, task_idx)\n",
    "\n",
    "        out = self.act2(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class conv_unit(nn.Module):\n",
    "    '''\n",
    "    Conv3D with the addition of adapter, if applicable\n",
    "    '''\n",
    "    def __init__(self, nb_tasks, inChans, outChans, trainMode: str, module, kernel_size: int=3, stride: int=1, padding: int=1) -> None:\n",
    "        super(conv_unit, self).__init__()\n",
    "        self.stride = stride\n",
    "        self.trainMode = trainMode\n",
    "        self.module = module\n",
    "\n",
    "        if self.stride !=1:\n",
    "            self.conv = nn.Conv3d(inChans, outChans, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "        elif self.stride == 1:\n",
    "            if trainMode != 'universal': # If not universal, then use generic U-Net setup\n",
    "                self.conv = nn.Conv3d(inChans, outChans, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "            \n",
    "            elif module in ['series_adapter', 'parallel_adapter']:\n",
    "                self.conv = nn.Conv3d(inChans, outChans, kernel_size=kernel_size, stride=stride, padding=padding) # padding != 0 for stride != 2 if doing padding=SAME.\n",
    "                if module == 'series_adapter':\n",
    "                    self.adapOps = nn.ModuleList([conv1x1(outChans, module) for i in range(nb_tasks)]) # based on https://github.com/srebuffi/residual_adapters/\n",
    "                elif module == 'parallel_adapter':\n",
    "                    self.adapOps = nn.ModuleList([conv1x1(inChans,module,outChans) for i in range(nb_tasks)]) \n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "            elif module == 'separable_adapter':\n",
    "                self.adapOps = nn.ModuleList([dwise(inChans) for i in range(nb_tasks)])\n",
    "                self.pwise = pwise(inChans, outChans)\n",
    "\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        # Effectively batch normalization\n",
    "        self.op = nn.ModuleList([norm_act(outChans, meth='norm') for i in range(nb_tasks)])\n",
    "\n",
    "\n",
    "    def forward(self, x, task_idx: int):\n",
    "        # import ipdb; ipdb.set_trace()\n",
    "        if self.stride != 1:\n",
    "            out = self.conv(x)\n",
    "            out = self.op[task_idx](out)\n",
    "            return out\n",
    "        elif self.stride == 1:\n",
    "            if self.trainMode != 'universal': # independent, shared\n",
    "                out = self.conv(x)\n",
    "                out = self.op[task_idx](out)\n",
    "            else: #universal\n",
    "                if self.module in ['series_adapter', 'parallel_adapter']:\n",
    "                    out = self.conv(x)\n",
    "                    if self.module == 'series_adapter':\n",
    "                        out = self.adapOps[task_idx](out)\n",
    "                    elif self.module == 'parallel_adapter':\n",
    "                        share_map = out\n",
    "                        para_map = self.adapOps[task_idx](x)\n",
    "                        out = out + para_map\n",
    "                    else:\n",
    "                        pass\n",
    "\n",
    "                    out = self.op[task_idx](out)\n",
    "                    if self.module == 'parallel_adapter':\n",
    "                        return out, share_map, para_map # for visualization of feature maps\n",
    "                    else:\n",
    "                        return out\n",
    "                elif self.module == 'separable_adapter':\n",
    "                    out = self.adapOps[task_idx](x)\n",
    "                    para_map = out\n",
    "                    out = self.pwise(out)\n",
    "                    share_map = out\n",
    "                    out = self.op[task_idx](out)\n",
    "                    return out, share_map, para_map\n",
    "                else:\n",
    "                    raise NotImplementedError(f'Adapter type: {self.module} not implemented')\n",
    "\n",
    "\n",
    "class dwise(nn.Module):\n",
    "    '''Depthwise convolution+normalization'''\n",
    "    def __init__(self, inChans, kernel_size: int=3, stride: int=1, padding: int=1) -> None:\n",
    "        super(dwise, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(inChans, inChans, kernel_size=kernel_size, stride=stride, padding=padding, groups=inChans) #By setting groups=inChans, the kernels are only applied to single channels\n",
    "        self.op1 = norm_act(inChans,meth='both')\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        out = self.conv1(x)\n",
    "        out = self.op1(out)\n",
    "        return out\n",
    "\n",
    "class pwise(nn.Module):\n",
    "    '''Pointwise convolution?\n",
    "    '''\n",
    "    def __init__(self, inChans:int, outChans:int, kernel_size: int=1, stride: int=1, padding: int=0) -> None:\n",
    "        super(pwise, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(inChans, outChans, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "\n",
    "    def forward(self, x) -> torch.Tensor:\n",
    "        out = self.conv1(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class InputTransition(nn.Module):\n",
    "    '''\n",
    "    task specific\n",
    "    '''\n",
    "    def __init__(self, inChans, base_outChans):\n",
    "        super(InputTransition, self).__init__()\n",
    "        self.op1 = nn.Sequential(\n",
    "            nn.Conv3d(inChans, base_outChans, kernel_size=3, stride=1, padding=1),\n",
    "            norm_act(base_outChans)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.op1(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "class OutputTransition(nn.Module):\n",
    "    '''\n",
    "    task specific\n",
    "    '''\n",
    "    def __init__(self, inChans, num_class):\n",
    "        super(OutputTransition, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(inChans, num_class, kernel_size=1, stride=1, padding=0)\n",
    "       \n",
    "    def forward(self, x, deep_supervision=None):\n",
    "        out = self.conv1(x)\n",
    "        if deep_supervision is None:\n",
    "            return out\n",
    "        else:\n",
    "            out = torch.add(out, deep_supervision)\n",
    "            return out\n",
    "\n",
    "\n",
    "class conv1x1(nn.Module):\n",
    "    def __init__(self, inChans, module, outChans=None, stride=1, padding=0):\n",
    "        super(conv1x1, self).__init__()\n",
    "        self.module = module\n",
    "        if self.module == 'series_adapter':\n",
    "            self.op1 = nn.Sequential(\n",
    "                norm_act(inChans,meth='norm'),\n",
    "                nn.Conv3d(inChans, inChans, kernel_size=1, stride=1)\n",
    "                )\n",
    "        elif self.module == 'parallel_adapter':\n",
    "            self.op1 = nn.Conv3d(inChans, outChans, kernel_size=1, stride=stride, padding=padding)\n",
    "        else: #separable adapter\n",
    "            self.op1 = nn.Conv3d(inChans, inChans, kernel_size=1, stride=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.op1(x)\n",
    "        if self.module == 'series_adapter':\n",
    "            out += x\n",
    "        return out\n",
    "\n",
    "def norm_act(nchan, meth='both'):\n",
    "    '''The normalization activation function, or what normalization you are applying to the\n",
    "    data. Either a InstanceNorm3D for meth='norm', a Leaky ReLU for meth = 'act', \n",
    "    or an LeakyReLU(InstanceNorm3D(x)) for meth='both'\n",
    "     '''\n",
    "    norm = nn.InstanceNorm3d(nchan, affine=True) #Calculates the mean and standard deviation across each individual channel for a single example and uses that to normalize values\n",
    "    # act = nn.ReLU() # activation\n",
    "    act = nn.LeakyReLU(negative_slope=1e-2)\n",
    "    if meth=='norm':\n",
    "        return norm\n",
    "    elif meth=='act':\n",
    "        return act\n",
    "    else:\n",
    "        return nn.Sequential(norm, act)\n",
    "\n",
    "class DeepSupervision(nn.Module):\n",
    "    '''\n",
    "    task specific\n",
    "    '''\n",
    "    def __init__(self, inChans, num_class, up_stride=(2,2,2)):\n",
    "        super(DeepSupervision, self).__init__()\n",
    "        self.op1 = nn.Sequential(\n",
    "            nn.Conv3d(inChans, num_class, kernel_size=1, stride=1, padding=0),\n",
    "            norm_act(num_class)\n",
    "        ) \n",
    "        self.op2 = Upsample3D(scale_factor=up_stride)\n",
    "\n",
    "    def forward(self, x, deep_supervision):\n",
    "        if deep_supervision is None:\n",
    "            out = self.op1(x)\n",
    "        else:\n",
    "            out = torch.add(self.op1(x), deep_supervision)\n",
    "        out = self.op2(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "qq =  U2Net3D(inChans_list = [1], num_pool_per_axis = [3,3,3], num_class_list=[2], trainMode = 'universal') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset\n",
    "\n",
    "IMPORTANT: Patch size must be a power of 2, otherwise the downsampling and upsampling will not match with each other for the skip connections (see encoding and decoding for loops of the U2Net3D). For example:\n",
    "```\n",
    "Downsampling: 60x60 -> 30x30 -> 15x15 -> 7x7\n",
    "Upsampling: 7x7 -> 14x14 -> 28x28 -> 56x56\n",
    "\n",
    "torch.cat(15x15, 14x14) = ERROR\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image and Lable file locations updated\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([], [])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat = UData('../data/U2Net/Task02_Heart/imagesTr/', '../data/U2Net/Task02_Heart/labelsTr/','../data/U2Net/Task02_Heart/patch_imgTR/','../data/U2Net/Task02_Heart/patch_labTR/')\n",
    "# pros_dat = UData('../data/U2Net/Task05_Prostate/imagesTr/', '../data/U2Net/Task05_Prostate/labelsTr/','../data/U2Net/Task05_Prostate/patch_imgTR/','../data/U2Net/Task05_Prostate/patch_labTR/')\n",
    "\n",
    "#dat.run(clear=True, save=True, contain_lab=True)\n",
    "dat.match_files('../data/U2Net/Task02_Heart/patch_imgTR/','../data/U2Net/Task02_Heart/patch_labTR/', update=True, paths=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dat.out_label_files) == len(dat.out_img_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, u2_class, label: int) -> None:\n",
    "        self.u2_class = u2_class\n",
    "        self.lab = label\n",
    "\n",
    "    def __len__(self)->int:\n",
    "        return len(self.u2_class.out_img_files)\n",
    "    \n",
    "    def __getitem__(self, index) -> 'tuple[torch.Tensor, torch.Tensor]':\n",
    "        X, Y = self.u2_class.load_image_pair(index)\n",
    "\n",
    "        X = torch.unsqueeze(torch.tensor(X, dtype=torch.float32),0)\n",
    "        Y = torch.unsqueeze(torch.tensor(Y, dtype=torch.float32),0)\n",
    "\n",
    "        return X,Y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DataLoader\n",
    "Data loader need to also provide some sort of identification based on the dataset being used if `universal` is the `self.trainMode` value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size': 4,\n",
    "        'shuffle': True,\n",
    "        'num_workers': 3}\n",
    "\n",
    "training_set = Dataset(dat, 0)\n",
    "training_generator = torch.utils.data.DataLoader(training_set, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lovasz Loss Function:\n",
    "Taken from https://github.com/bermanmaxim/LovaszSoftmax/blob/master/pytorch/lovasz_losses.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from itertools import  filterfalse as ifilterfalse\n",
    "\n",
    "\n",
    "def lovasz_softmax(probas, labels, only_present=False, per_image=False, ignore=None):\n",
    "    \"\"\"\n",
    "    Multi-class Lovasz-Softmax loss\n",
    "      probas: [B, C, H, W] Variable, class probabilities at each prediction (between 0 and 1)\n",
    "      labels: [B, H, W] Tensor, ground truth labels (between 0 and C - 1)\n",
    "      only_present: average only on classes present in ground truth\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class labels\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        loss = mean(lovasz_softmax_flat(*flatten_probas(prob.unsqueeze(0), lab.unsqueeze(0), ignore), only_present=only_present)\n",
    "                          for prob, lab in zip(probas, labels))\n",
    "    else:\n",
    "        loss = lovasz_softmax_flat(*flatten_probas(probas, labels, ignore), only_present=only_present)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_softmax_flat(probas, labels, only_present=False):\n",
    "    \"\"\"\n",
    "    Multi-class Lovasz-Softmax loss\n",
    "      probas: [P, C] Variable, class probabilities at each prediction (between 0 and 1)\n",
    "      labels: [P] Tensor, ground truth labels (between 0 and C - 1)\n",
    "      only_present: average only on classes present in ground truth\n",
    "    \"\"\"\n",
    "    if probas.numel() == 0:\n",
    "        # only void pixels, the gradients should be 0\n",
    "        return probas * 0.\n",
    "    C = probas.size(1)\n",
    "    \n",
    "    C = probas.size(1)\n",
    "    losses = []\n",
    "    for c in range(C):\n",
    "        fg = (labels == c).float() # foreground for class c\n",
    "        if only_present and fg.sum() == 0:\n",
    "            continue\n",
    "        errors = (Variable(fg) - probas[:, c]).abs()\n",
    "        errors_sorted, perm = torch.sort(errors, 0, descending=True)\n",
    "        perm = perm.data\n",
    "        fg_sorted = fg[perm]\n",
    "        losses.append(torch.dot(errors_sorted, Variable(lovasz_grad(fg_sorted))))\n",
    "    return mean(losses)\n",
    "\n",
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    p = len(gt_sorted)\n",
    "    gts = gt_sorted.sum()\n",
    "    intersection = gts - gt_sorted.float().cumsum(0)\n",
    "    union = gts + (1 - gt_sorted).float().cumsum(0)\n",
    "    jaccard = 1. - intersection / union\n",
    "    if p > 1: # cover 1-pixel case\n",
    "        jaccard[1:p] = jaccard[1:p] - jaccard[0:-1]\n",
    "    return jaccard\n",
    "\n",
    "\n",
    "def flatten_probas(probas, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch\n",
    "    \"\"\"\n",
    "    probas = probas.view(probas.size(0), probas.size(1), -1)    # N,C,H,W => N,C,H*W\n",
    "    probas = probas.transpose(1, 2) # N,C,H*W => N,H*W,C\n",
    "    probas = probas.contiguous().view(-1, probas.size(2))\n",
    "\n",
    "    labels = labels.view(-1)\n",
    "    if ignore is None:\n",
    "        return probas, labels\n",
    "    valid = (labels != ignore)\n",
    "    vprobas = probas[valid.nonzero().squeeze()]\n",
    "    vlabels = labels[valid]\n",
    "    return vprobas, vlabels\n",
    "\n",
    "def mean(l, ignore_nan=False, empty=0):\n",
    "    \"\"\"\n",
    "    nanmean compatible with generators.\n",
    "    \"\"\"\n",
    "    l = iter(l)\n",
    "    if ignore_nan:\n",
    "        l = ifilterfalse(isnan, l)\n",
    "    try:\n",
    "        n = 1\n",
    "        acc = next(l)\n",
    "    except StopIteration:\n",
    "        if empty == 'raise':\n",
    "            raise ValueError('Empty mean')\n",
    "        return empty\n",
    "    for n, v in enumerate(l, 2):\n",
    "        acc += v\n",
    "    if n == 1:\n",
    "        return acc\n",
    "    return acc / n\n",
    "\n",
    "def xloss(logits, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Cross entropy loss\n",
    "    \"\"\"\n",
    "    return F.cross_entropy(logits, Variable(labels), ignore_index=255)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Focal Loss:\n",
    "Commented section taken from https://github.com/clcarwin/focal_loss_pytorch/blob/master/focalloss.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=0, alpha=None, size_average=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        if isinstance(alpha,(float,int)): self.alpha = torch.Tensor([alpha,1-alpha])\n",
    "        if isinstance(alpha,list): self.alpha = torch.Tensor(alpha)\n",
    "        self.size_average = size_average\n",
    "\n",
    "    # def forward(self, input, target):\n",
    "    #     if input.dim()>2:\n",
    "    #         input = input.view(input.size(0),input.size(1),-1)  # N,C,H,W => N,C,H*W\n",
    "    #         input = input.transpose(1,2)    # N,C,H*W => N,H*W,C\n",
    "    #         input = input.contiguous().view(-1,input.size(2))   # N,H*W,C => N*H*W,C\n",
    "    #     target = target.view(-1,1)\n",
    "\n",
    "    #     logpt = F.log_softmax(input)\n",
    "    #     logpt = logpt.gather(1,target)\n",
    "    #     logpt = logpt.view(-1)\n",
    "    #     pt = Variable(logpt.data.exp())\n",
    "\n",
    "    #     if self.alpha is not None:\n",
    "    #         if self.alpha.type()!=input.data.type():\n",
    "    #             self.alpha = self.alpha.type_as(input.data)\n",
    "    #         at = self.alpha.gather(0,target.data.view(-1))\n",
    "    #         logpt = logpt * Variable(at)\n",
    "\n",
    "    #     loss = -1 * (1-pt)**self.gamma * logpt\n",
    "    #     if self.size_average: \n",
    "    #         return loss.mean()\n",
    "    #     else: \n",
    "    #         return loss.sum()\n",
    "\n",
    "    def forward(self, input, target, classes='all'):\n",
    "        if classes in ['all']:\n",
    "            # print(f'size of input = {input.shape}')\n",
    "            # print(f'size of target = {target.shape}')\n",
    "            if input.dim()>2:\n",
    "                input = input.view(input.size(0),input.size(1),-1)  # N,C,H,W => N,C,H*W\n",
    "                input = input.transpose(1,2)    # N,C,H*W => N,H*W,C\n",
    "                input = input.contiguous().view(-1,input.size(2))   # N,H*W,C => N*H*W,C\n",
    "            target = target.view(-1,1).long()\n",
    "            # print(f'size of post-viewed target is {target.shape}')\n",
    "            # print(f'sample of post-viewed target: {target[:5,0]}')\n",
    "\n",
    "            logpt = F.log_softmax(input, 1)\n",
    "            # print(f'size of logpt is {logpt.shape}')\n",
    "            # print(f'sample of logpt: {logpt[:5,:]}')\n",
    "            logpt = logpt.gather(1,target) #https://stackoverflow.com/questions/50999977/what-does-the-gather-function-do-in-pytorch-in-layman-terms\n",
    "            logpt = logpt.view(-1)\n",
    "            pt = Variable(logpt.data.exp())\n",
    "\n",
    "            if self.alpha is not None:\n",
    "                if self.alpha.type()!=input.data.type():\n",
    "                    self.alpha = self.alpha.type_as(input.data)\n",
    "                at = self.alpha.gather(0,target.data.view(-1))\n",
    "                logpt = logpt * Variable(at)\n",
    "\n",
    "            loss = -1 * (1-pt)**self.gamma * logpt\n",
    "            if self.size_average: return loss.mean()\n",
    "            else: return loss.sum()\n",
    "\n",
    "        elif isinstance(classes, list):\n",
    "            if input.dim()>2:\n",
    "                input = input.view(input.size(0),input.size(1),-1)  # N,C,H,W => N,C,H*W\n",
    "                input = input.transpose(1,2)    # N,C,H*W => N,H*W,C\n",
    "                input = input.contiguous().view(-1,input.size(2))   # N,H*W,C => N*H*W,C\n",
    "            # target = target.view(-1,1).long()\n",
    "\n",
    "            # alpha is pixel-wise weight??\n",
    "            if self.alpha is not None:\n",
    "                if self.alpha.type()!=input.data.type():\n",
    "                    self.alpha = self.alpha.type_as(input.data)\n",
    "\n",
    "            logpt = F.log_softmax(input, 1)\n",
    "\n",
    "            # borrow from lovasz_loss\n",
    "            C = input.size(1)\n",
    "            loss = []\n",
    "            class_to_sum = list(range(C)) if classes in ['all', 'present'] else classes\n",
    "\n",
    "            for c in class_to_sum:\n",
    "                fg = (target == c).float() # foreground for class c\n",
    "                class_pred = logpt[:,c]\n",
    "                if (classes == 'present' and fg.sum() == 0):\n",
    "                    continue\n",
    "                logpt = torch.dot(class_pred, fg)\n",
    "                if self.alpha is not None:\n",
    "                    class_alpha = (self.alpha == c).float()\n",
    "                    logpt *= class_alpha\n",
    "                pt = logpt.data.exp()\n",
    "                class_loss = -1 * (1-pt)**self.gamma * logpt\n",
    "                loss.append(class_loss)\n",
    "            loss = torch.tensor(loss).type(input.dtype)\n",
    "            if self.size_average: \n",
    "                return loss.mean()\n",
    "            else: \n",
    "                return loss.sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0003\n",
    "weight_decay = 5e-4\n",
    "\n",
    "optimizer = torch.optim.Adam(qq.parameters(), lr=lr, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "max_epochs = 5\n",
    "\n",
    "focal_loss = FocalLoss(gamma=2)\n",
    "acc_loss = []\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "\n",
    "    for inp, goal in tqdm(training_generator):\n",
    "        optimizer.zero_grad()\n",
    "        # print(inp.shape)\n",
    "        test_output, share_map, para_map = qq(inp,0)\n",
    "        # print(f'Size of test_output is : {test_output.shape}') # Only care about 'out', not 'share_map' or 'para_map'\n",
    "        \n",
    "        output_softmax = F.softmax(test_output, dim=1)\n",
    "        # print(f'size of output_softmax is {output_softmax.shape}')\n",
    "\n",
    "        loss = lovasz_softmax(output_softmax, goal, ignore=10) + focal_loss(test_output, goal)\n",
    "\n",
    "        print(f'Loss value of {loss}')\n",
    "        acc_loss.append(loss)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    time.sleep(120)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the loss values over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f5b8f0e3af0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "\n",
    "loc = 40\n",
    "\n",
    "a = axs[0].imshow(output_softmax[0,1,loc,:,:].detach().numpy())\n",
    "b = axs[1].imshow(goal[0,0,loc,:,:].detach().numpy())\n",
    "plt.colorbar(a, ax=axs[0])\n",
    "plt.colorbar(b, ax=axs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit ('3.8.7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "539b544e2c3fdc58492248d082a132f5e0b4fea63e914fb274c32873997cf2f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
